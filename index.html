<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Skip-Vision: Efficient and Scalable Acceleration of Vision-Language Models via Adaptive Token Skipping">
  <meta name="keywords" content="Skip-Vision, Efficiency, Scalability, Training time, FLOPs, Latency">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Skip-Vision: Efficient and Scalable Acceleration of Vision-Language Models via Adaptive Token Skipping</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<style>
    .pulse {
        animation: pulse 2s infinite;
    }
    .highlighted {
        font-size: 1.5em;
        color: #e74c3c;
        font-weight: bold;
        margin-bottom: 0.5em;
      }
    @keyframes pulse {
        0% { transform: scale(1); box-shadow: 0 0 0 0 rgba(255, 87, 34, 0.7); }
        70% { transform: scale(1.05); box-shadow: 0 0 0 10px rgba(255, 87, 34, 0); }
        100% { transform: scale(1); box-shadow: 0 0 0 0 rgba(255, 87, 34, 0); }
    }
</style>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Skip-Vision: Efficient and Scalable Acceleration of Vision-Language Models via Adaptive Token Skipping</h1>
          <div class="is-size-5 publication-authors">
            <div class="highlighted">ICCV 2025</div>
            <span class="author-block">
              Weili Zeng</a><sup>1</sup>,</span>
            <span class="author-block">
              Ziyuan Huang</a><sup>1</sup>,</span>
            <span class="author-block">
              Kaixiang Ji</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://daodaofr.github.io/">Yichao Yan</a><sup>1</sup>,</span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Shanghai Jiao Tong University</span>
            <span class="author-block"><sup>1</sup>Ant Group</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2503.21817"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/zwl666666/Skip-Vision"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="./static/images/framework-new.png"
                 class="interpolation-image"
                 alt="Interpolate start reference image."/>
      <h2 class="subtitle has-text-centered">
        <b>The framework of Skip-Vision.</b> a) While visual scaling enriches visual information, it also increases computational overhead. Skip-Vision uses a skip-FFN strategy during training to reduce redundant computation for visual tokens. The numerous skipped tokens will be limited to the attention layer and bypass FFN. b) At the beginning of inference, Skip-Vision will remove skip-FFN visual tokens from the initial KV-cache, enhancing efficiency. c) During inference, skip attention leverages the skip KV-cache to accelerate generation.
      </h2>
    </div>
  </div>
</section>

<style>
    .small-image {
        width: 200px; 
        height: auto; 
    }
    .responsive-image {
        max-width: 80%; 
        height: auto;  
    }
</style>
<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Transformer-based models have driven significant advancements in Multimodal Large Language Models (MLLMs), yet their computational costs surge drastically when scaling resolution, training data, and model parameters. A key bottleneck stems from the proliferation of visual tokens required for fine-grained image understanding. We propose Skip-Vision, a unified framework addressing both training and inference inefficiencies in vision-language models. On top of conventional token compression approaches, our method introduces two complementary acceleration strategies. 
            For training acceleration, we observe that Feed-Forward Network (FFN) computations on visual tokens induce marginal feature updates. This motivates our Skip-FFN strategy, which bypasses FFN layers for redundant visual tokens. For inference acceleration, we design a selective KV-cache removal mechanism that prunes the skipped key-value pairs during decoding while preserving model performance. 
          </p>
            Experimental results demonstrate that Skip-Vision reduces training time by up to 35%, inference FLOPs by 75%, and latency by 45%, while achieving comparable or superior performance to existing methods. Our work provides a practical solution for scaling high-performance MLLMs with enhanced efficiency.
          <p>
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Performance-efficiency. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Performance-efficiency trade-off</h2>
        <img src="./static/images/tradeoff-new.png"
                 class="responsive-image"
                 alt="Interpolate start reference image."/>
        <div class="content has-text-justified">
          <p>
            <b>Performance-efficiency trade-off curve.</b> Each circle denotes a model configuration, where our models utilize
              the Skip-Vision framework, with CoS, LLava-HD and LLaVA serving as baselines. Circle sizes reflect the inference FLOPs ratio. Skip-Vision demonstrate superior performance,
              scaling effectively with increased FLOPs and data and achieving higher inference efficiency when compared to baselines and other effcient MLLM methods. All methods utilize LLaMA3 8B as the
              foundational large language model.
          </p>
        </div>
      </div>
    </div>
    <!--/ Performance-efficiency. -->
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="./static/images/single.png"
                 class="interpolation-image"
                 alt="Interpolate start reference image."/>
    </div>
  </div>
</section>
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="./static/images/more.png"
                 class="interpolation-image"
                 alt="Interpolate start reference image."/>
    </div>
  </div>
</section>
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="./static/images/multi_concept_samples_new.png"
                 class="interpolation-image"
                 alt="Interpolate start reference image."/>
    </div>
  </div>
</section>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@misc{zeng2025skipvisionefficientscalableacceleration,
      title={Skip-Vision: Efficient and Scalable Acceleration of Vision-Language Models via Adaptive Token Skipping}, 
      author={Weili Zeng and Ziyuan Huang and Kaixiang Ji and Yichao Yan},
      year={2025},
      eprint={2503.21817},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2503.21817}, 
}
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/Skip-Vision.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/zwl666666/Skip-Vision" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
