<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Skip-Vision: Efficient and Scalable Acceleration of Vision-Language Models via Adaptive Token Skipping">
  <meta name="keywords" content="Skip-Vision, Efficiency, Scalability, Training time, FLOPs, Latency">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Skip-Vision: Efficient and Scalable Acceleration of Vision-Language Models via Adaptive Token Skipping</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<style>
    .pulse {
        animation: pulse 2s infinite;
    }
    .highlighted {
        font-size: 1.5em;
        color: #e74c3c;
        font-weight: bold;
        margin-bottom: 0.5em;
      }
    @keyframes pulse {
        0% { transform: scale(1); box-shadow: 0 0 0 0 rgba(255, 87, 34, 0.7); }
        70% { transform: scale(1.05); box-shadow: 0 0 0 10px rgba(255, 87, 34, 0); }
        100% { transform: scale(1); box-shadow: 0 0 0 0 rgba(255, 87, 34, 0); }
    }
</style>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Skip-Vision: Efficient and Scalable Acceleration of Vision-Language Models via Adaptive Token Skipping</h1>
          <div class="is-size-5 publication-authors">
            <div class="highlighted">ICCV 2025</div>
            <span class="author-block">
              Weili Zeng</a><sup>1</sup>,</span>
            <span class="author-block">
              Ziyuan Huang</a><sup>1</sup>,</span>
            <span class="author-block">
              Kaixiang Ji</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://daodaofr.github.io/">Yichao Yan</a><sup>1</sup>,</span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Shanghai Jiao Tong University</span>
            <span class="author-block"><sup>1</sup>Ant Group</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2503.21817"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/zwl666666/Skip-Vision"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="./static/images/framework-new.png"
                 class="interpolation-image"
                 alt="Interpolate start reference image."/>
      <h2 class="subtitle has-text-centered">
        The framework of Skip-Vision. a) While visual scaling enriches visual information, it also increases computational overhead. Skip-Vision uses a skip-FFN strategy during training to reduce redundant computation for visual tokens. The numerous skipped tokens will be limited to the attention layer and bypass FFN. b) At the beginning of inference, Skip-Vision will remove skip-FFN visual tokens from the initial KV-cache, enhancing efficiency. c) During inference, skip attention leverages the skip KV-cache to accelerate generation.
      </h2>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Text-to-image (T2I) customization aims to create images that embody specific visual concepts delineated in textual descriptions
          </p>
          <p>
            However, existing works still face a main challenge, concept overfitting. To tackle this challenge, we first analyze overfitting, categorizing
            it into concept-agnostic overfitting, which undermines non-customized concept knowledge, and concept-specific overfitting, 
            which is confined to customize on limited modalities, i.e, backgrounds, layouts, styles. To evaluate the overfitting degree, we 
            further introduce two metrics, i.e, Latent Fisher divergence and Wasserstein metric to measure the distribution changes of non-customized and customized concept respectively.
          </p>
          <p>
            Drawing from the analysis, we propose Infusion, a T2I customization method that enables the learning of target concepts to avoid being constrained
            by limited training modalities, while preserving non-customized knowledge. Remarkably, Infusion achieves this feat with remarkable
            efficiency, requiring a mere 11KB of trained parameters. Extensive experiments also demonstrate that our approach outperforms state-of-the-art 
            methods in both single and multi-concept customized generation.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper video. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <video id="replay-video"
                 controls
                 muted
                 preload
                 playsinline
                 width="100%">
            <source src="./static/videos/infusion_video.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div>
    <!--/ Paper video. -->
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="./static/images/single.png"
                 class="interpolation-image"
                 alt="Interpolate start reference image."/>
    </div>
  </div>
</section>
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="./static/images/more.png"
                 class="interpolation-image"
                 alt="Interpolate start reference image."/>
    </div>
  </div>
</section>
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="./static/images/multi_concept_samples_new.png"
                 class="interpolation-image"
                 alt="Interpolate start reference image."/>
    </div>
  </div>
</section>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@misc{zeng2024infusion,
      title={Infusion: Preventing Customized Text-to-Image Diffusion from Overfitting}, 
      author={Weili Zeng and Yichao Yan and Qi Zhu and Zhuo Chen and Pengzhi Chu and Weiming Zhao and Xiaokang Yang},
      year={2024},
      eprint={2404.14007},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/infusion.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/zwl666666/infusion" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
