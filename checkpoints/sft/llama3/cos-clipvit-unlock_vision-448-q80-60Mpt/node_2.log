[2024-08-26 17:26:42,943] torch.distributed.run: [WARNING] 
[2024-08-26 17:26:42,943] torch.distributed.run: [WARNING] *****************************************
[2024-08-26 17:26:42,943] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2024-08-26 17:26:42,943] torch.distributed.run: [WARNING] *****************************************
/opt/conda/envs/llava/lib/python3.10/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/opt/conda/envs/llava/lib/python3.10/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/opt/conda/envs/llava/lib/python3.10/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/opt/conda/envs/llava/lib/python3.10/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/opt/conda/envs/llava/lib/python3.10/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/opt/conda/envs/llava/lib/python3.10/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/opt/conda/envs/llava/lib/python3.10/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/opt/conda/envs/llava/lib/python3.10/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
llava models imported
llava models imported
llava models imported
llava models imported
llava models imported
llava models imported
llava models imported
llava models imported
[2024-08-26 17:27:22,036] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-08-26 17:27:22,050] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-08-26 17:27:22,050] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-08-26 17:27:22,096] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-08-26 17:27:22,097] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-08-26 17:27:22,110] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-08-26 17:27:22,112] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-08-26 17:27:22,138] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-08-26 17:27:22,185] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-08-26 17:27:22,198] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-08-26 17:27:22,205] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-08-26 17:27:22,250] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-08-26 17:27:22,251] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-08-26 17:27:22,265] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-08-26 17:27:22,269] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-08-26 17:27:22,299] [INFO] [comm.py:637:init_distributed] cdb=None
Converting image folder to dict
Loading path conversion file: ./playground/data/ocrvqa_path-conversion.json
You are using a model of type llama to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
Converting image folder to dict
Loading path conversion file: ./playground/data/ocrvqa_path-conversion.json
Converting image folder to dict
Loading path conversion file: ./playground/data/ocrvqa_path-conversion.json
Converting image folder to dict
Loading path conversion file: ./playground/data/ocrvqa_path-conversion.json
You are using a model of type llama to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
You are using a model of type llama to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
aieflopsvip-kmaker-033145109241:224067:224067 [3] NCCL INFO cudaDriverVersion 12010
aieflopsvip-kmaker-033145109241:224067:224067 [3] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0
aieflopsvip-kmaker-033145109241:224067:224067 [3] NCCL INFO Bootstrap : Using eth0:33.145.109.241<0>
aieflopsvip-kmaker-033145109241:224067:224067 [3] NCCL INFO NET/Plugin : dlerror=libnccl-net.so: cannot open shared object file: No such file or directory No plugin found (libnccl-net.so), using internal implementation
Converting image folder to dict
Loading path conversion file: ./playground/data/ocrvqa_path-conversion.json
aieflopsvip-kmaker-033145109241:224069:224069 [5] NCCL INFO cudaDriverVersion 12010
aieflopsvip-kmaker-033145109241:224069:224069 [5] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0
aieflopsvip-kmaker-033145109241:224069:224069 [5] NCCL INFO Bootstrap : Using eth0:33.145.109.241<0>
aieflopsvip-kmaker-033145109241:224069:224069 [5] NCCL INFO NET/Plugin : dlerror=libnccl-net.so: cannot open shared object file: No such file or directory No plugin found (libnccl-net.so), using internal implementation
You are using a model of type llama to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
aieflopsvip-kmaker-033145109241:224064:224064 [0] NCCL INFO cudaDriverVersion 12010
aieflopsvip-kmaker-033145109241:224064:224064 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0
aieflopsvip-kmaker-033145109241:224064:224064 [0] NCCL INFO Bootstrap : Using eth0:33.145.109.241<0>
aieflopsvip-kmaker-033145109241:224064:224064 [0] NCCL INFO NET/Plugin : dlerror=libnccl-net.so: cannot open shared object file: No such file or directory No plugin found (libnccl-net.so), using internal implementation
aieflopsvip-kmaker-033145109241:224069:224169 [5] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0
aieflopsvip-kmaker-033145109241:224067:224168 [3] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0
aieflopsvip-kmaker-033145109241:224069:224169 [5] NCCL INFO NCCL_IB_HCA set to mlx5
aieflopsvip-kmaker-033145109241:224067:224168 [3] NCCL INFO NCCL_IB_HCA set to mlx5
Converting image folder to dict
Loading path conversion file: ./playground/data/ocrvqa_path-conversion.json
aieflopsvip-kmaker-033145109241:224064:224170 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0
aieflopsvip-kmaker-033145109241:224064:224170 [0] NCCL INFO NCCL_IB_HCA set to mlx5
aieflopsvip-kmaker-033145109241:224070:224070 [6] NCCL INFO cudaDriverVersion 12010
aieflopsvip-kmaker-033145109241:224070:224070 [6] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0
aieflopsvip-kmaker-033145109241:224070:224070 [6] NCCL INFO Bootstrap : Using eth0:33.145.109.241<0>
aieflopsvip-kmaker-033145109241:224070:224070 [6] NCCL INFO NET/Plugin : dlerror=libnccl-net.so: cannot open shared object file: No such file or directory No plugin found (libnccl-net.so), using internal implementation
aieflopsvip-kmaker-033145109241:224070:224175 [6] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0
aieflopsvip-kmaker-033145109241:224070:224175 [6] NCCL INFO NCCL_IB_HCA set to mlx5
aieflopsvip-kmaker-033145109241:224067:224168 [3] NCCL INFO NET/IB : Using [0]mlx5_1:1/RoCE [1]mlx5_57:1/RoCE [2]mlx5_113:1/RoCE [3]mlx5_169:1/RoCE [RO]; OOB eth0:33.145.109.241<0>
aieflopsvip-kmaker-033145109241:224067:224168 [3] NCCL INFO Using non-device net plugin version 0
aieflopsvip-kmaker-033145109241:224067:224168 [3] NCCL INFO Using network IB
aieflopsvip-kmaker-033145109241:224064:224170 [0] NCCL INFO NET/IB : Using [0]mlx5_1:1/RoCE [1]mlx5_57:1/RoCE [2]mlx5_113:1/RoCE [3]mlx5_169:1/RoCE [RO]; OOB eth0:33.145.109.241<0>
aieflopsvip-kmaker-033145109241:224064:224170 [0] NCCL INFO Using non-device net plugin version 0
aieflopsvip-kmaker-033145109241:224064:224170 [0] NCCL INFO Using network IB
aieflopsvip-kmaker-033145109241:224069:224169 [5] NCCL INFO NET/IB : Using [0]mlx5_1:1/RoCE [1]mlx5_57:1/RoCE [2]mlx5_113:1/RoCE [3]mlx5_169:1/RoCE [RO]; OOB eth0:33.145.109.241<0>
aieflopsvip-kmaker-033145109241:224069:224169 [5] NCCL INFO Using non-device net plugin version 0
aieflopsvip-kmaker-033145109241:224069:224169 [5] NCCL INFO Using network IB
aieflopsvip-kmaker-033145109241:224070:224175 [6] NCCL INFO NET/IB : Using [0]mlx5_1:1/RoCE [1]mlx5_57:1/RoCE [2]mlx5_113:1/RoCE [3]mlx5_169:1/RoCE [RO]; OOB eth0:33.145.109.241<0>
aieflopsvip-kmaker-033145109241:224070:224175 [6] NCCL INFO Using non-device net plugin version 0
aieflopsvip-kmaker-033145109241:224070:224175 [6] NCCL INFO Using network IB
You are using a model of type llama to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
aieflopsvip-kmaker-033145109241:224071:224071 [7] NCCL INFO cudaDriverVersion 12010
aieflopsvip-kmaker-033145109241:224071:224071 [7] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0
aieflopsvip-kmaker-033145109241:224071:224071 [7] NCCL INFO Bootstrap : Using eth0:33.145.109.241<0>
aieflopsvip-kmaker-033145109241:224071:224071 [7] NCCL INFO NET/Plugin : dlerror=libnccl-net.so: cannot open shared object file: No such file or directory No plugin found (libnccl-net.so), using internal implementation
You are using a model of type llama to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
aieflopsvip-kmaker-033145109241:224071:224188 [7] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0
aieflopsvip-kmaker-033145109241:224071:224188 [7] NCCL INFO NCCL_IB_HCA set to mlx5
aieflopsvip-kmaker-033145109241:224066:224066 [2] NCCL INFO cudaDriverVersion 12010
aieflopsvip-kmaker-033145109241:224066:224066 [2] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0
aieflopsvip-kmaker-033145109241:224066:224066 [2] NCCL INFO Bootstrap : Using eth0:33.145.109.241<0>
aieflopsvip-kmaker-033145109241:224066:224066 [2] NCCL INFO NET/Plugin : dlerror=libnccl-net.so: cannot open shared object file: No such file or directory No plugin found (libnccl-net.so), using internal implementation
aieflopsvip-kmaker-033145109241:224066:224191 [2] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0
aieflopsvip-kmaker-033145109241:224066:224191 [2] NCCL INFO NCCL_IB_HCA set to mlx5
aieflopsvip-kmaker-033145109241:224071:224188 [7] NCCL INFO NET/IB : Using [0]mlx5_1:1/RoCE [1]mlx5_57:1/RoCE [2]mlx5_113:1/RoCE [3]mlx5_169:1/RoCE [RO]; OOB eth0:33.145.109.241<0>
aieflopsvip-kmaker-033145109241:224071:224188 [7] NCCL INFO Using non-device net plugin version 0
aieflopsvip-kmaker-033145109241:224071:224188 [7] NCCL INFO Using network IB
aieflopsvip-kmaker-033145109241:224066:224191 [2] NCCL INFO NET/IB : Using [0]mlx5_1:1/RoCE [1]mlx5_57:1/RoCE [2]mlx5_113:1/RoCE [3]mlx5_169:1/RoCE [RO]; OOB eth0:33.145.109.241<0>
aieflopsvip-kmaker-033145109241:224066:224191 [2] NCCL INFO Using non-device net plugin version 0
aieflopsvip-kmaker-033145109241:224066:224191 [2] NCCL INFO Using network IB
Converting image folder to dict
Loading path conversion file: ./playground/data/ocrvqa_path-conversion.json
Converting image folder to dict
Loading path conversion file: ./playground/data/ocrvqa_path-conversion.json
You are using a model of type llama to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
You are using a model of type llama to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
aieflopsvip-kmaker-033145109241:224065:224065 [1] NCCL INFO cudaDriverVersion 12010
aieflopsvip-kmaker-033145109241:224065:224065 [1] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0
aieflopsvip-kmaker-033145109241:224065:224065 [1] NCCL INFO Bootstrap : Using eth0:33.145.109.241<0>
aieflopsvip-kmaker-033145109241:224065:224065 [1] NCCL INFO NET/Plugin : dlerror=libnccl-net.so: cannot open shared object file: No such file or directory No plugin found (libnccl-net.so), using internal implementation
aieflopsvip-kmaker-033145109241:224065:224200 [1] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0
aieflopsvip-kmaker-033145109241:224065:224200 [1] NCCL INFO NCCL_IB_HCA set to mlx5
aieflopsvip-kmaker-033145109241:224068:224068 [4] NCCL INFO cudaDriverVersion 12010
aieflopsvip-kmaker-033145109241:224068:224068 [4] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0
aieflopsvip-kmaker-033145109241:224065:224200 [1] NCCL INFO NET/IB : Using [0]mlx5_1:1/RoCE [1]mlx5_57:1/RoCE [2]mlx5_113:1/RoCE [3]mlx5_169:1/RoCE [RO]; OOB eth0:33.145.109.241<0>
aieflopsvip-kmaker-033145109241:224065:224200 [1] NCCL INFO Using non-device net plugin version 0
aieflopsvip-kmaker-033145109241:224065:224200 [1] NCCL INFO Using network IB
aieflopsvip-kmaker-033145109241:224068:224068 [4] NCCL INFO Bootstrap : Using eth0:33.145.109.241<0>
aieflopsvip-kmaker-033145109241:224068:224068 [4] NCCL INFO NET/Plugin : dlerror=libnccl-net.so: cannot open shared object file: No such file or directory No plugin found (libnccl-net.so), using internal implementation
aieflopsvip-kmaker-033145109241:224068:224205 [4] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0
aieflopsvip-kmaker-033145109241:224068:224205 [4] NCCL INFO NCCL_IB_HCA set to mlx5
aieflopsvip-kmaker-033145109241:224068:224205 [4] NCCL INFO NET/IB : Using [0]mlx5_1:1/RoCE [1]mlx5_57:1/RoCE [2]mlx5_113:1/RoCE [3]mlx5_169:1/RoCE [RO]; OOB eth0:33.145.109.241<0>
aieflopsvip-kmaker-033145109241:224068:224205 [4] NCCL INFO Using non-device net plugin version 0
aieflopsvip-kmaker-033145109241:224068:224205 [4] NCCL INFO Using network IB
aieflopsvip-kmaker-033145109241:224071:224188 [7] NCCL INFO comm 0x7ab87540 rank 23 nranks 32 cudaDev 7 nvmlDev 7 busId b3000 commId 0x55d07b2619d4d57f - Init START
aieflopsvip-kmaker-033145109241:224070:224175 [6] NCCL INFO comm 0x7b2c8f10 rank 22 nranks 32 cudaDev 6 nvmlDev 6 busId ad000 commId 0x55d07b2619d4d57f - Init START
aieflopsvip-kmaker-033145109241:224069:224169 [5] NCCL INFO comm 0x79ef1c10 rank 21 nranks 32 cudaDev 5 nvmlDev 5 busId 8e000 commId 0x55d07b2619d4d57f - Init START
aieflopsvip-kmaker-033145109241:224068:224205 [4] NCCL INFO comm 0x7a94b7e0 rank 20 nranks 32 cudaDev 4 nvmlDev 4 busId 89000 commId 0x55d07b2619d4d57f - Init START
aieflopsvip-kmaker-033145109241:224066:224191 [2] NCCL INFO comm 0x79c85990 rank 18 nranks 32 cudaDev 2 nvmlDev 2 busId 48000 commId 0x55d07b2619d4d57f - Init START
aieflopsvip-kmaker-033145109241:224065:224200 [1] NCCL INFO comm 0x7a00ce90 rank 17 nranks 32 cudaDev 1 nvmlDev 1 busId 19000 commId 0x55d07b2619d4d57f - Init START
aieflopsvip-kmaker-033145109241:224064:224170 [0] NCCL INFO comm 0x984789c0 rank 16 nranks 32 cudaDev 0 nvmlDev 0 busId 13000 commId 0x55d07b2619d4d57f - Init START
aieflopsvip-kmaker-033145109241:224067:224168 [3] NCCL INFO comm 0x7af2d110 rank 19 nranks 32 cudaDev 3 nvmlDev 3 busId 4d000 commId 0x55d07b2619d4d57f - Init START
aieflopsvip-kmaker-033145109241:224070:224175 [6] NCCL INFO Setting affinity for GPU 6 to ffffffff,00000000,ffffffff,00000000
aieflopsvip-kmaker-033145109241:224070:224175 [6] NCCL INFO NVLS multicast support is not available on dev 6
aieflopsvip-kmaker-033145109241:224069:224169 [5] NCCL INFO Setting affinity for GPU 5 to ffffffff,00000000,ffffffff,00000000
aieflopsvip-kmaker-033145109241:224069:224169 [5] NCCL INFO NVLS multicast support is not available on dev 5
aieflopsvip-kmaker-033145109241:224067:224168 [3] NCCL INFO Setting affinity for GPU 3 to ffffffff,00000000,ffffffff
aieflopsvip-kmaker-033145109241:224067:224168 [3] NCCL INFO NVLS multicast support is not available on dev 3
aieflopsvip-kmaker-033145109241:224068:224205 [4] NCCL INFO Setting affinity for GPU 4 to ffffffff,00000000,ffffffff,00000000
aieflopsvip-kmaker-033145109241:224068:224205 [4] NCCL INFO NVLS multicast support is not available on dev 4
aieflopsvip-kmaker-033145109241:224071:224188 [7] NCCL INFO Setting affinity for GPU 7 to ffffffff,00000000,ffffffff,00000000
aieflopsvip-kmaker-033145109241:224071:224188 [7] NCCL INFO NVLS multicast support is not available on dev 7
aieflopsvip-kmaker-033145109241:224064:224170 [0] NCCL INFO Setting affinity for GPU 0 to ffffffff,00000000,ffffffff
aieflopsvip-kmaker-033145109241:224064:224170 [0] NCCL INFO NVLS multicast support is not available on dev 0
aieflopsvip-kmaker-033145109241:224065:224200 [1] NCCL INFO Setting affinity for GPU 1 to ffffffff,00000000,ffffffff
aieflopsvip-kmaker-033145109241:224065:224200 [1] NCCL INFO NVLS multicast support is not available on dev 1
aieflopsvip-kmaker-033145109241:224066:224191 [2] NCCL INFO Setting affinity for GPU 2 to ffffffff,00000000,ffffffff
aieflopsvip-kmaker-033145109241:224066:224191 [2] NCCL INFO NVLS multicast support is not available on dev 2
aieflopsvip-kmaker-033145109241:224066:224191 [2] NCCL INFO Trees [0] 19/-1/-1->18->17 [1] 19/26/-1->18->2 [2] 19/-1/-1->18->17 [3] 19/-1/-1->18->17 [4] 19/-1/-1->18->17 [5] 19/-1/-1->18->11 [6] 19/-1/-1->18->17 [7] 19/-1/-1->18->17
aieflopsvip-kmaker-033145109241:224066:224191 [2] NCCL INFO P2P Chunksize set to 131072
aieflopsvip-kmaker-033145109241:224071:224188 [7] NCCL INFO Trees [0] -1/-1/-1->23->22 [1] 16/-1/-1->23->22 [2] 16/-1/-1->23->22 [3] 16/14/-1->23->22 [4] -1/-1/-1->23->22 [5] 16/-1/-1->23->22 [6] 16/-1/-1->23->22 [7] 16/-1/-1->23->22
aieflopsvip-kmaker-033145109241:224070:224175 [6] NCCL INFO Trees [0] 23/-1/-1->22->21 [1] 23/-1/-1->22->21 [2] 23/-1/-1->22->21 [3] 23/30/-1->22->6 [4] 23/-1/-1->22->21 [5] 23/-1/-1->22->21 [6] 23/-1/-1->22->21 [7] 23/-1/-1->22->15
aieflopsvip-kmaker-033145109241:224068:224205 [4] NCCL INFO Trees [0] 21/-1/-1->20->19 [1] 21/-1/-1->20->19 [2] 21/28/-1->20->4 [3] 21/-1/-1->20->19 [4] 21/-1/-1->20->19 [5] 21/-1/-1->20->19 [6] 21/-1/-1->20->13 [7] 21/-1/-1->20->19
aieflopsvip-kmaker-033145109241:224067:224168 [3] NCCL INFO Trees [0] 20/-1/-1->19->18 [1] 20/10/-1->19->18 [2] -1/-1/-1->19->18 [3] 20/-1/-1->19->18 [4] 20/-1/-1->19->18 [5] 20/-1/-1->19->18 [6] -1/-1/-1->19->18 [7] 20/-1/-1->19->18
aieflopsvip-kmaker-033145109241:224071:224188 [7] NCCL INFO P2P Chunksize set to 131072
aieflopsvip-kmaker-033145109241:224069:224169 [5] NCCL INFO Trees [0] 22/-1/-1->21->20 [1] 22/-1/-1->21->20 [2] 22/12/-1->21->20 [3] -1/-1/-1->21->20 [4] 22/-1/-1->21->20 [5] 22/-1/-1->21->20 [6] 22/-1/-1->21->20 [7] -1/-1/-1->21->20
aieflopsvip-kmaker-033145109241:224070:224175 [6] NCCL INFO P2P Chunksize set to 131072
aieflopsvip-kmaker-033145109241:224068:224205 [4] NCCL INFO P2P Chunksize set to 131072
aieflopsvip-kmaker-033145109241:224067:224168 [3] NCCL INFO P2P Chunksize set to 131072
aieflopsvip-kmaker-033145109241:224069:224169 [5] NCCL INFO P2P Chunksize set to 131072
aieflopsvip-kmaker-033145109241:224065:224200 [1] NCCL INFO Trees [0] 18/8/-1->17->16 [1] -1/-1/-1->17->16 [2] 18/-1/-1->17->16 [3] 18/-1/-1->17->16 [4] 18/-1/-1->17->16 [5] -1/-1/-1->17->16 [6] 18/-1/-1->17->16 [7] 18/-1/-1->17->16
aieflopsvip-kmaker-033145109241:224065:224200 [1] NCCL INFO P2P Chunksize set to 131072
aieflopsvip-kmaker-033145109241:224064:224170 [0] NCCL INFO Trees [0] 17/24/-1->16->0 [1] 17/-1/-1->16->23 [2] 17/-1/-1->16->23 [3] 17/-1/-1->16->23 [4] 17/-1/-1->16->9 [5] 17/-1/-1->16->23 [6] 17/-1/-1->16->23 [7] 17/-1/-1->16->23
aieflopsvip-kmaker-033145109241:224064:224170 [0] NCCL INFO P2P Chunksize set to 131072
aieflopsvip-kmaker-033145109241:224070:224175 [6] NCCL INFO Channel 03/0 : 15[7] -> 22[6] [receive] via NET/IB/2/GDRDMA
aieflopsvip-kmaker-033145109241:224070:224175 [6] NCCL INFO Channel 07/0 : 15[7] -> 22[6] [receive] via NET/IB/2/GDRDMA
aieflopsvip-kmaker-033145109241:224068:224205 [4] NCCL INFO Channel 02/0 : 13[5] -> 20[4] [receive] via NET/IB/1/GDRDMA
aieflopsvip-kmaker-033145109241:224068:224205 [4] NCCL INFO Channel 06/0 : 13[5] -> 20[4] [receive] via NET/IB/1/GDRDMA
aieflopsvip-kmaker-033145109241:224069:224169 [5] NCCL INFO Channel 02/0 : 21[5] -> 28[4] [send] via NET/IB/1/GDRDMA
aieflopsvip-kmaker-033145109241:224069:224169 [5] NCCL INFO Channel 06/0 : 21[5] -> 28[4] [send] via NET/IB/1/GDRDMA
aieflopsvip-kmaker-033145109241:224064:224170 [0] NCCL INFO Channel 00/0 : 9[1] -> 16[0] [receive] via NET/IB/0/GDRDMA
aieflopsvip-kmaker-033145109241:224064:224170 [0] NCCL INFO Channel 04/0 : 9[1] -> 16[0] [receive] via NET/IB/0/GDRDMA
aieflopsvip-kmaker-033145109241:224064:224170 [0] NCCL INFO Channel 00/0 : 16[0] -> 23[7] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224065:224200 [1] NCCL INFO Channel 00/0 : 17[1] -> 24[0] [send] via NET/IB/0/GDRDMA
aieflopsvip-kmaker-033145109241:224065:224200 [1] NCCL INFO Channel 04/0 : 17[1] -> 24[0] [send] via NET/IB/0/GDRDMA
aieflopsvip-kmaker-033145109241:224066:224191 [2] NCCL INFO Channel 01/0 : 11[3] -> 18[2] [receive] via NET/IB/3/GDRDMA
aieflopsvip-kmaker-033145109241:224066:224191 [2] NCCL INFO Channel 05/0 : 11[3] -> 18[2] [receive] via NET/IB/3/GDRDMA
aieflopsvip-kmaker-033145109241:224067:224168 [3] NCCL INFO Channel 01/0 : 19[3] -> 26[2] [send] via NET/IB/3/GDRDMA
aieflopsvip-kmaker-033145109241:224067:224168 [3] NCCL INFO Channel 05/0 : 19[3] -> 26[2] [send] via NET/IB/3/GDRDMA
aieflopsvip-kmaker-033145109241:224064:224170 [0] NCCL INFO Channel 01/0 : 16[0] -> 23[7] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224064:224170 [0] NCCL INFO Channel 02/0 : 16[0] -> 23[7] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224064:224170 [0] NCCL INFO Channel 03/0 : 16[0] -> 23[7] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224064:224170 [0] NCCL INFO Channel 04/0 : 16[0] -> 23[7] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224064:224170 [0] NCCL INFO Channel 05/0 : 16[0] -> 23[7] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224068:224205 [4] NCCL INFO Channel 00/0 : 20[4] -> 19[3] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224070:224175 [6] NCCL INFO Channel 00/0 : 22[6] -> 21[5] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224064:224170 [0] NCCL INFO Channel 06/0 : 16[0] -> 23[7] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224071:224188 [7] NCCL INFO Channel 03/0 : 23[7] -> 30[6] [send] via NET/IB/2/GDRDMA
aieflopsvip-kmaker-033145109241:224071:224188 [7] NCCL INFO Channel 07/0 : 23[7] -> 30[6] [send] via NET/IB/2/GDRDMA
aieflopsvip-kmaker-033145109241:224068:224205 [4] NCCL INFO Channel 01/0 : 20[4] -> 19[3] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224070:224175 [6] NCCL INFO Channel 01/0 : 22[6] -> 21[5] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224064:224170 [0] NCCL INFO Channel 07/0 : 16[0] -> 23[7] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224066:224191 [2] NCCL INFO Channel 00/0 : 18[2] -> 17[1] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224068:224205 [4] NCCL INFO Channel 02/0 : 20[4] -> 19[3] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224070:224175 [6] NCCL INFO Channel 02/0 : 22[6] -> 21[5] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224069:224169 [5] NCCL INFO Channel 00/0 : 21[5] -> 20[4] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224071:224188 [7] NCCL INFO Channel 00/0 : 23[7] -> 22[6] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224065:224200 [1] NCCL INFO Channel 01/0 : 17[1] -> 16[0] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224066:224191 [2] NCCL INFO Channel 01/0 : 18[2] -> 17[1] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224067:224168 [3] NCCL INFO Channel 00/0 : 19[3] -> 18[2] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224068:224205 [4] NCCL INFO Channel 03/0 : 20[4] -> 19[3] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224070:224175 [6] NCCL INFO Channel 03/0 : 22[6] -> 21[5] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224069:224169 [5] NCCL INFO Channel 01/0 : 21[5] -> 20[4] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224071:224188 [7] NCCL INFO Channel 01/0 : 23[7] -> 22[6] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224065:224200 [1] NCCL INFO Channel 02/0 : 17[1] -> 16[0] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224066:224191 [2] NCCL INFO Channel 02/0 : 18[2] -> 17[1] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224067:224168 [3] NCCL INFO Channel 02/0 : 19[3] -> 18[2] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224068:224205 [4] NCCL INFO Channel 04/0 : 20[4] -> 19[3] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224070:224175 [6] NCCL INFO Channel 04/0 : 22[6] -> 21[5] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224069:224169 [5] NCCL INFO Channel 03/0 : 21[5] -> 20[4] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224071:224188 [7] NCCL INFO Channel 02/0 : 23[7] -> 22[6] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224065:224200 [1] NCCL INFO Channel 03/0 : 17[1] -> 16[0] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224066:224191 [2] NCCL INFO Channel 03/0 : 18[2] -> 17[1] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224067:224168 [3] NCCL INFO Channel 03/0 : 19[3] -> 18[2] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224068:224205 [4] NCCL INFO Channel 05/0 : 20[4] -> 19[3] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224070:224175 [6] NCCL INFO Channel 05/0 : 22[6] -> 21[5] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224069:224169 [5] NCCL INFO Channel 04/0 : 21[5] -> 20[4] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224071:224188 [7] NCCL INFO Channel 04/0 : 23[7] -> 22[6] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224065:224200 [1] NCCL INFO Channel 05/0 : 17[1] -> 16[0] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224066:224191 [2] NCCL INFO Channel 04/0 : 18[2] -> 17[1] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224067:224168 [3] NCCL INFO Channel 04/0 : 19[3] -> 18[2] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224068:224205 [4] NCCL INFO Channel 06/0 : 20[4] -> 19[3] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224070:224175 [6] NCCL INFO Channel 06/0 : 22[6] -> 21[5] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224069:224169 [5] NCCL INFO Channel 05/0 : 21[5] -> 20[4] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224071:224188 [7] NCCL INFO Channel 05/0 : 23[7] -> 22[6] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224065:224200 [1] NCCL INFO Channel 06/0 : 17[1] -> 16[0] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224066:224191 [2] NCCL INFO Channel 05/0 : 18[2] -> 17[1] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224067:224168 [3] NCCL INFO Channel 06/0 : 19[3] -> 18[2] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224068:224205 [4] NCCL INFO Channel 07/0 : 20[4] -> 19[3] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224070:224175 [6] NCCL INFO Channel 07/0 : 22[6] -> 21[5] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224069:224169 [5] NCCL INFO Channel 07/0 : 21[5] -> 20[4] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224071:224188 [7] NCCL INFO Channel 06/0 : 23[7] -> 22[6] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224065:224200 [1] NCCL INFO Channel 07/0 : 17[1] -> 16[0] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224066:224191 [2] NCCL INFO Channel 06/0 : 18[2] -> 17[1] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224067:224168 [3] NCCL INFO Channel 07/0 : 19[3] -> 18[2] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224066:224191 [2] NCCL INFO Channel 07/0 : 18[2] -> 17[1] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224069:224215 [5] NCCL INFO NCCL_IB_GID_INDEX set by environment to 3.
aieflopsvip-kmaker-033145109241:224066:224211 [2] NCCL INFO NCCL_IB_GID_INDEX set by environment to 3.
aieflopsvip-kmaker-033145109241:224066:224211 [2] NCCL INFO NCCL_IB_TC set by environment to 136.
aieflopsvip-kmaker-033145109241:224066:224211 [2] NCCL INFO NCCL_IB_SL set by environment to 5.
aieflopsvip-kmaker-033145109241:224066:224211 [2] NCCL INFO NCCL_IB_TIMEOUT set by environment to 22.
aieflopsvip-kmaker-033145109241:224065:224216 [1] NCCL INFO NCCL_IB_GID_INDEX set by environment to 3.
aieflopsvip-kmaker-033145109241:224068:224212 [4] NCCL INFO NCCL_IB_GID_INDEX set by environment to 3.
aieflopsvip-kmaker-033145109241:224068:224212 [4] NCCL INFO NCCL_IB_TC set by environment to 136.
aieflopsvip-kmaker-033145109241:224068:224212 [4] NCCL INFO NCCL_IB_SL set by environment to 5.
aieflopsvip-kmaker-033145109241:224068:224212 [4] NCCL INFO NCCL_IB_TIMEOUT set by environment to 22.
aieflopsvip-kmaker-033145109241:224067:224217 [3] NCCL INFO NCCL_IB_GID_INDEX set by environment to 3.
aieflopsvip-kmaker-033145109241:224069:224215 [5] NCCL INFO NCCL_IB_TC set by environment to 136.
aieflopsvip-kmaker-033145109241:224069:224215 [5] NCCL INFO NCCL_IB_SL set by environment to 5.
aieflopsvip-kmaker-033145109241:224069:224215 [5] NCCL INFO NCCL_IB_TIMEOUT set by environment to 22.
aieflopsvip-kmaker-033145109241:224067:224217 [3] NCCL INFO NCCL_IB_TC set by environment to 136.
aieflopsvip-kmaker-033145109241:224067:224217 [3] NCCL INFO NCCL_IB_SL set by environment to 5.
aieflopsvip-kmaker-033145109241:224067:224217 [3] NCCL INFO NCCL_IB_TIMEOUT set by environment to 22.
aieflopsvip-kmaker-033145109241:224064:224218 [0] NCCL INFO NCCL_IB_GID_INDEX set by environment to 3.
aieflopsvip-kmaker-033145109241:224064:224218 [0] NCCL INFO NCCL_IB_TC set by environment to 136.
aieflopsvip-kmaker-033145109241:224064:224218 [0] NCCL INFO NCCL_IB_SL set by environment to 5.
aieflopsvip-kmaker-033145109241:224064:224218 [0] NCCL INFO NCCL_IB_TIMEOUT set by environment to 22.
aieflopsvip-kmaker-033145109241:224070:224213 [6] NCCL INFO NCCL_IB_GID_INDEX set by environment to 3.
aieflopsvip-kmaker-033145109241:224070:224213 [6] NCCL INFO NCCL_IB_TC set by environment to 136.
aieflopsvip-kmaker-033145109241:224070:224213 [6] NCCL INFO NCCL_IB_SL set by environment to 5.
aieflopsvip-kmaker-033145109241:224070:224213 [6] NCCL INFO NCCL_IB_TIMEOUT set by environment to 22.
aieflopsvip-kmaker-033145109241:224065:224216 [1] NCCL INFO NCCL_IB_TC set by environment to 136.
aieflopsvip-kmaker-033145109241:224065:224216 [1] NCCL INFO NCCL_IB_SL set by environment to 5.
aieflopsvip-kmaker-033145109241:224065:224216 [1] NCCL INFO NCCL_IB_TIMEOUT set by environment to 22.
aieflopsvip-kmaker-033145109241:224071:224214 [7] NCCL INFO NCCL_IB_GID_INDEX set by environment to 3.
aieflopsvip-kmaker-033145109241:224071:224214 [7] NCCL INFO NCCL_IB_TC set by environment to 136.
aieflopsvip-kmaker-033145109241:224071:224214 [7] NCCL INFO NCCL_IB_SL set by environment to 5.
aieflopsvip-kmaker-033145109241:224071:224214 [7] NCCL INFO NCCL_IB_TIMEOUT set by environment to 22.
aieflopsvip-kmaker-033145109241:224067:224168 [3] NCCL INFO Connected all rings
aieflopsvip-kmaker-033145109241:224068:224205 [4] NCCL INFO Connected all rings
aieflopsvip-kmaker-033145109241:224069:224169 [5] NCCL INFO Connected all rings
aieflopsvip-kmaker-033145109241:224064:224170 [0] NCCL INFO Connected all rings
aieflopsvip-kmaker-033145109241:224064:224170 [0] NCCL INFO Channel 00/0 : 16[0] -> 17[1] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224066:224191 [2] NCCL INFO Connected all rings
aieflopsvip-kmaker-033145109241:224065:224200 [1] NCCL INFO Connected all rings
aieflopsvip-kmaker-033145109241:224064:224170 [0] NCCL INFO Channel 01/0 : 16[0] -> 17[1] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224070:224175 [6] NCCL INFO Connected all rings
aieflopsvip-kmaker-033145109241:224071:224188 [7] NCCL INFO Connected all rings
aieflopsvip-kmaker-033145109241:224068:224205 [4] NCCL INFO Channel 00/0 : 20[4] -> 21[5] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224064:224170 [0] NCCL INFO Channel 02/0 : 16[0] -> 17[1] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224067:224168 [3] NCCL INFO Channel 00/0 : 19[3] -> 20[4] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224068:224205 [4] NCCL INFO Channel 01/0 : 20[4] -> 21[5] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224069:224169 [5] NCCL INFO Channel 00/0 : 21[5] -> 22[6] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224067:224168 [3] NCCL INFO Channel 01/0 : 19[3] -> 20[4] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224064:224170 [0] NCCL INFO Channel 03/0 : 16[0] -> 17[1] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224068:224205 [4] NCCL INFO Channel 02/0 : 20[4] -> 21[5] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224069:224169 [5] NCCL INFO Channel 01/0 : 21[5] -> 22[6] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224067:224168 [3] NCCL INFO Channel 03/0 : 19[3] -> 20[4] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224064:224170 [0] NCCL INFO Channel 04/0 : 16[0] -> 17[1] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224068:224205 [4] NCCL INFO Channel 03/0 : 20[4] -> 21[5] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224069:224169 [5] NCCL INFO Channel 02/0 : 21[5] -> 22[6] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224067:224168 [3] NCCL INFO Channel 04/0 : 19[3] -> 20[4] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224064:224170 [0] NCCL INFO Channel 05/0 : 16[0] -> 17[1] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224068:224205 [4] NCCL INFO Channel 04/0 : 20[4] -> 21[5] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224069:224169 [5] NCCL INFO Channel 04/0 : 21[5] -> 22[6] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224067:224168 [3] NCCL INFO Channel 05/0 : 19[3] -> 20[4] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224064:224170 [0] NCCL INFO Channel 06/0 : 16[0] -> 17[1] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224066:224191 [2] NCCL INFO Channel 00/0 : 18[2] -> 19[3] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224068:224205 [4] NCCL INFO Channel 05/0 : 20[4] -> 21[5] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224069:224169 [5] NCCL INFO Channel 05/0 : 21[5] -> 22[6] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224067:224168 [3] NCCL INFO Channel 07/0 : 19[3] -> 20[4] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224064:224170 [0] NCCL INFO Channel 07/0 : 16[0] -> 17[1] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224066:224191 [2] NCCL INFO Channel 01/0 : 18[2] -> 19[3] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224070:224175 [6] NCCL INFO Channel 00/0 : 22[6] -> 23[7] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224068:224205 [4] NCCL INFO Channel 06/0 : 20[4] -> 21[5] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224069:224169 [5] NCCL INFO Channel 06/0 : 21[5] -> 22[6] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224066:224191 [2] NCCL INFO Channel 02/0 : 18[2] -> 19[3] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224070:224175 [6] NCCL INFO Channel 01/0 : 22[6] -> 23[7] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224068:224205 [4] NCCL INFO Channel 07/0 : 20[4] -> 21[5] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224065:224200 [1] NCCL INFO Channel 00/0 : 17[1] -> 18[2] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224066:224191 [2] NCCL INFO Channel 03/0 : 18[2] -> 19[3] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224070:224175 [6] NCCL INFO Channel 02/0 : 22[6] -> 23[7] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224065:224200 [1] NCCL INFO Channel 02/0 : 17[1] -> 18[2] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224068:224205 [4] NCCL INFO Channel 02/0 : 20[4] -> 28[4] [send] via NET/IB/1/GDRDMA
aieflopsvip-kmaker-033145109241:224066:224191 [2] NCCL INFO Channel 04/0 : 18[2] -> 19[3] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224070:224175 [6] NCCL INFO Channel 03/0 : 22[6] -> 23[7] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224065:224200 [1] NCCL INFO Channel 03/0 : 17[1] -> 18[2] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224066:224191 [2] NCCL INFO Channel 05/0 : 18[2] -> 19[3] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224070:224175 [6] NCCL INFO Channel 04/0 : 22[6] -> 23[7] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224065:224200 [1] NCCL INFO Channel 04/0 : 17[1] -> 18[2] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224066:224191 [2] NCCL INFO Channel 06/0 : 18[2] -> 19[3] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224070:224175 [6] NCCL INFO Channel 05/0 : 22[6] -> 23[7] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224065:224200 [1] NCCL INFO Channel 06/0 : 17[1] -> 18[2] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224066:224191 [2] NCCL INFO Channel 07/0 : 18[2] -> 19[3] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224070:224175 [6] NCCL INFO Channel 06/0 : 22[6] -> 23[7] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224065:224200 [1] NCCL INFO Channel 07/0 : 17[1] -> 18[2] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224067:224168 [3] NCCL INFO Channel 01/0 : 10[2] -> 19[3] [receive] via NET/IB/3/GDRDMA
aieflopsvip-kmaker-033145109241:224070:224175 [6] NCCL INFO Channel 07/0 : 22[6] -> 23[7] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224064:224170 [0] NCCL INFO Channel 00/0 : 16[0] -> 24[0] [send] via NET/IB/0/GDRDMA
aieflopsvip-kmaker-033145109241:224066:224191 [2] NCCL INFO Channel 01/0 : 18[2] -> 26[2] [send] via NET/IB/3/GDRDMA
aieflopsvip-kmaker-033145109241:224065:224200 [1] NCCL INFO Channel 00/0 : 8[0] -> 17[1] [receive] via NET/IB/0/GDRDMA
aieflopsvip-kmaker-033145109241:224069:224169 [5] NCCL INFO Channel 02/0 : 12[4] -> 21[5] [receive] via NET/IB/1/GDRDMA
aieflopsvip-kmaker-033145109241:224070:224175 [6] NCCL INFO Channel 03/0 : 22[6] -> 30[6] [send] via NET/IB/2/GDRDMA
aieflopsvip-kmaker-033145109241:224071:224188 [7] NCCL INFO Channel 03/0 : 14[6] -> 23[7] [receive] via NET/IB/2/GDRDMA
aieflopsvip-kmaker-033145109241:224064:224170 [0] NCCL INFO Channel 00/0 : 0[0] -> 16[0] [receive] via NET/IB/0/GDRDMA
aieflopsvip-kmaker-033145109241:224066:224191 [2] NCCL INFO Channel 01/0 : 2[2] -> 18[2] [receive] via NET/IB/3/GDRDMA
aieflopsvip-kmaker-033145109241:224064:224170 [0] NCCL INFO Channel 00/0 : 16[0] -> 0[0] [send] via NET/IB/0/GDRDMA
aieflopsvip-kmaker-033145109241:224066:224191 [2] NCCL INFO Channel 01/0 : 18[2] -> 2[2] [send] via NET/IB/3/GDRDMA
aieflopsvip-kmaker-033145109241:224065:224200 [1] NCCL INFO Channel 00/0 : 17[1] -> 8[0] [send] via NET/IB/0/GDRDMA
aieflopsvip-kmaker-033145109241:224065:224200 [1] NCCL INFO Channel 00/0 : 17[1] -> 16[0] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224065:224200 [1] NCCL INFO Channel 04/0 : 17[1] -> 16[0] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224064:224170 [0] NCCL INFO Channel 00/0 : 24[0] -> 16[0] [receive] via NET/IB/0/GDRDMA
aieflopsvip-kmaker-033145109241:224064:224170 [0] NCCL INFO Channel 04/0 : 16[0] -> 9[1] [send] via NET/IB/0/GDRDMA
aieflopsvip-kmaker-033145109241:224070:224175 [6] NCCL INFO Channel 03/0 : 6[6] -> 22[6] [receive] via NET/IB/2/GDRDMA
aieflopsvip-kmaker-033145109241:224070:224175 [6] NCCL INFO Channel 03/0 : 22[6] -> 6[6] [send] via NET/IB/2/GDRDMA
aieflopsvip-kmaker-033145109241:224068:224205 [4] NCCL INFO Channel 02/0 : 4[4] -> 20[4] [receive] via NET/IB/1/GDRDMA
aieflopsvip-kmaker-033145109241:224068:224205 [4] NCCL INFO Channel 02/0 : 20[4] -> 4[4] [send] via NET/IB/1/GDRDMA
aieflopsvip-kmaker-033145109241:224070:224175 [6] NCCL INFO Channel 03/0 : 30[6] -> 22[6] [receive] via NET/IB/2/GDRDMA
aieflopsvip-kmaker-033145109241:224071:224188 [7] NCCL INFO Channel 03/0 : 23[7] -> 14[6] [send] via NET/IB/2/GDRDMA
aieflopsvip-kmaker-033145109241:224071:224188 [7] NCCL INFO Channel 01/0 : 23[7] -> 16[0] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224070:224175 [6] NCCL INFO Channel 07/0 : 22[6] -> 15[7] [send] via NET/IB/2/GDRDMA
aieflopsvip-kmaker-033145109241:224068:224205 [4] NCCL INFO Channel 02/0 : 28[4] -> 20[4] [receive] via NET/IB/1/GDRDMA
aieflopsvip-kmaker-033145109241:224071:224188 [7] NCCL INFO Channel 02/0 : 23[7] -> 16[0] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224069:224169 [5] NCCL INFO Channel 02/0 : 21[5] -> 12[4] [send] via NET/IB/1/GDRDMA
aieflopsvip-kmaker-033145109241:224069:224169 [5] NCCL INFO Channel 02/0 : 21[5] -> 20[4] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224068:224205 [4] NCCL INFO Channel 06/0 : 20[4] -> 13[5] [send] via NET/IB/1/GDRDMA
aieflopsvip-kmaker-033145109241:224071:224188 [7] NCCL INFO Channel 03/0 : 23[7] -> 16[0] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224066:224191 [2] NCCL INFO Channel 01/0 : 26[2] -> 18[2] [receive] via NET/IB/3/GDRDMA
aieflopsvip-kmaker-033145109241:224069:224169 [5] NCCL INFO Channel 06/0 : 21[5] -> 20[4] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224071:224188 [7] NCCL INFO Channel 05/0 : 23[7] -> 16[0] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224071:224188 [7] NCCL INFO Channel 06/0 : 23[7] -> 16[0] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224071:224188 [7] NCCL INFO Channel 07/0 : 23[7] -> 16[0] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224067:224168 [3] NCCL INFO Channel 01/0 : 19[3] -> 10[2] [send] via NET/IB/3/GDRDMA
aieflopsvip-kmaker-033145109241:224066:224191 [2] NCCL INFO Channel 05/0 : 18[2] -> 11[3] [send] via NET/IB/3/GDRDMA
aieflopsvip-kmaker-033145109241:224067:224168 [3] NCCL INFO Channel 01/0 : 19[3] -> 18[2] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224067:224168 [3] NCCL INFO Channel 05/0 : 19[3] -> 18[2] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224071:224188 [7] NCCL INFO Channel 03/0 : 23[7] -> 22[6] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224071:224188 [7] NCCL INFO Channel 07/0 : 23[7] -> 22[6] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224069:224169 [5] NCCL INFO Connected all trees
aieflopsvip-kmaker-033145109241:224068:224205 [4] NCCL INFO Connected all trees
aieflopsvip-kmaker-033145109241:224069:224169 [5] NCCL INFO threadThresholds 8/8/64 | 256/8/64 | 512 | 512
aieflopsvip-kmaker-033145109241:224069:224169 [5] NCCL INFO 8 coll channels, 0 nvls channels, 8 p2p channels, 2 p2p channels per peer
aieflopsvip-kmaker-033145109241:224068:224205 [4] NCCL INFO threadThresholds 8/8/64 | 256/8/64 | 512 | 512
aieflopsvip-kmaker-033145109241:224068:224205 [4] NCCL INFO 8 coll channels, 0 nvls channels, 8 p2p channels, 2 p2p channels per peer
aieflopsvip-kmaker-033145109241:224066:224191 [2] NCCL INFO Connected all trees
aieflopsvip-kmaker-033145109241:224067:224168 [3] NCCL INFO Connected all trees
aieflopsvip-kmaker-033145109241:224066:224191 [2] NCCL INFO threadThresholds 8/8/64 | 256/8/64 | 512 | 512
aieflopsvip-kmaker-033145109241:224067:224168 [3] NCCL INFO threadThresholds 8/8/64 | 256/8/64 | 512 | 512
aieflopsvip-kmaker-033145109241:224066:224191 [2] NCCL INFO 8 coll channels, 0 nvls channels, 8 p2p channels, 2 p2p channels per peer
aieflopsvip-kmaker-033145109241:224067:224168 [3] NCCL INFO 8 coll channels, 0 nvls channels, 8 p2p channels, 2 p2p channels per peer
aieflopsvip-kmaker-033145109241:224065:224200 [1] NCCL INFO Connected all trees
aieflopsvip-kmaker-033145109241:224071:224188 [7] NCCL INFO Connected all trees
aieflopsvip-kmaker-033145109241:224070:224175 [6] NCCL INFO Connected all trees
aieflopsvip-kmaker-033145109241:224064:224170 [0] NCCL INFO Connected all trees
aieflopsvip-kmaker-033145109241:224065:224200 [1] NCCL INFO threadThresholds 8/8/64 | 256/8/64 | 512 | 512
aieflopsvip-kmaker-033145109241:224071:224188 [7] NCCL INFO threadThresholds 8/8/64 | 256/8/64 | 512 | 512
aieflopsvip-kmaker-033145109241:224065:224200 [1] NCCL INFO 8 coll channels, 0 nvls channels, 8 p2p channels, 2 p2p channels per peer
aieflopsvip-kmaker-033145109241:224071:224188 [7] NCCL INFO 8 coll channels, 0 nvls channels, 8 p2p channels, 2 p2p channels per peer
aieflopsvip-kmaker-033145109241:224070:224175 [6] NCCL INFO threadThresholds 8/8/64 | 256/8/64 | 512 | 512
aieflopsvip-kmaker-033145109241:224070:224175 [6] NCCL INFO 8 coll channels, 0 nvls channels, 8 p2p channels, 2 p2p channels per peer
aieflopsvip-kmaker-033145109241:224064:224170 [0] NCCL INFO threadThresholds 8/8/64 | 256/8/64 | 512 | 512
aieflopsvip-kmaker-033145109241:224064:224170 [0] NCCL INFO 8 coll channels, 0 nvls channels, 8 p2p channels, 2 p2p channels per peer
aieflopsvip-kmaker-033145109241:224071:224188 [7] NCCL INFO comm 0x7ab87540 rank 23 nranks 32 cudaDev 7 nvmlDev 7 busId b3000 commId 0x55d07b2619d4d57f - Init COMPLETE
aieflopsvip-kmaker-033145109241:224065:224200 [1] NCCL INFO comm 0x7a00ce90 rank 17 nranks 32 cudaDev 1 nvmlDev 1 busId 19000 commId 0x55d07b2619d4d57f - Init COMPLETE
aieflopsvip-kmaker-033145109241:224068:224205 [4] NCCL INFO comm 0x7a94b7e0 rank 20 nranks 32 cudaDev 4 nvmlDev 4 busId 89000 commId 0x55d07b2619d4d57f - Init COMPLETE
aieflopsvip-kmaker-033145109241:224064:224170 [0] NCCL INFO comm 0x984789c0 rank 16 nranks 32 cudaDev 0 nvmlDev 0 busId 13000 commId 0x55d07b2619d4d57f - Init COMPLETE
aieflopsvip-kmaker-033145109241:224069:224169 [5] NCCL INFO comm 0x79ef1c10 rank 21 nranks 32 cudaDev 5 nvmlDev 5 busId 8e000 commId 0x55d07b2619d4d57f - Init COMPLETE
aieflopsvip-kmaker-033145109241:224066:224191 [2] NCCL INFO comm 0x79c85990 rank 18 nranks 32 cudaDev 2 nvmlDev 2 busId 48000 commId 0x55d07b2619d4d57f - Init COMPLETE
aieflopsvip-kmaker-033145109241:224067:224168 [3] NCCL INFO comm 0x7af2d110 rank 19 nranks 32 cudaDev 3 nvmlDev 3 busId 4d000 commId 0x55d07b2619d4d57f - Init COMPLETE
aieflopsvip-kmaker-033145109241:224070:224175 [6] NCCL INFO comm 0x7b2c8f10 rank 22 nranks 32 cudaDev 6 nvmlDev 6 busId ad000 commId 0x55d07b2619d4d57f - Init COMPLETE
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:01<00:03,  1.10s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:02,  1.11it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:02,  1.04it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:01<00:03,  1.02s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:01<00:03,  1.03s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:01<00:03,  1.08s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:02,  1.01it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:01<00:03,  1.06s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:02<00:02,  1.22s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:02<00:02,  1.14s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:02<00:02,  1.17s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:02<00:02,  1.18s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:02<00:02,  1.19s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:02<00:02,  1.22s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:02<00:02,  1.20s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:02<00:02,  1.23s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:03<00:01,  1.18s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:03<00:01,  1.23s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:03<00:01,  1.21s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:03<00:01,  1.23s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:03<00:01,  1.21s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:03<00:01,  1.22s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:03<00:01,  1.22s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:03<00:01,  1.21s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.30it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.12it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.25it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.06it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.27it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.07it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.25it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.06it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.26it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.08it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.27it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.09it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.26it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.07it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.25it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.07it/s]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[RANK 17] initializing vision tower
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[RANK 18] initializing vision tower
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[RANK 22] initializing vision tower
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[RANK 16] initializing vision tower
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[RANK 23] initializing vision tower
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[RANK 19] initializing vision tower
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[RANK 20] initializing vision tower
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[RANK 21] initializing vision tower
Resizing position embedding grid-size from %s to %sResizing position embedding grid-size from %s to %s  (16, 16) (32, 32)(16, 16) 
(32, 32)
Resizing position embedding grid-size from %s to %s (16, 16) (32, 32)
[RANK 23] Loading state dict to CLIP VIT.
[RANK 22] Loading state dict to CLIP VIT.
[RANK 17] Loading state dict to CLIP VIT.
Resizing position embedding grid-size from %s to %s (16, 16) (32, 32)
Resizing position embedding grid-size from %s to %s (16, 16) (32, 32)
Resizing position embedding grid-size from %s to %s (16, 16) (32, 32)
[]
[]
[]
[RANK 18] Loading state dict to CLIP VIT.
[RANK 19] Loading state dict to CLIP VIT.
[RANK 20] Loading state dict to CLIP VIT.
[]
[]
[]
Resizing position embedding grid-size from %s to %s (16, 16) (32, 32)
[RANK 16] Loading state dict to CLIP VIT.
[]
Resizing position embedding grid-size from %s to %s (16, 16) (32, 32)
[RANK 21] Loading state dict to CLIP VIT.
[]
Building visual processor at the resolution of 448
Setting cls_token_w32_q16...
Setting cls_token_w8_q64...
Building visual processor at the resolution of 448
Setting cls_token_w32_q16...
Setting cls_token_w8_q64...
Building visual processor at the resolution of 448
Setting cls_token_w32_q16...
Setting cls_token_w8_q64...
Building visual processor at the resolution of 448
Setting cls_token_w32_q16...
Setting cls_token_w8_q64...
Building visual processor at the resolution of 448
Setting cls_token_w32_q16...
Setting cls_token_w8_q64...
Building visual processor at the resolution of 448
Setting cls_token_w32_q16...
Setting cls_token_w8_q64...
Building visual processor at the resolution of 448
Setting cls_token_w32_q16...
Setting cls_token_w8_q64...
Building visual processor at the resolution of 448
Setting cls_token_w32_q16...
Setting cls_token_w8_q64...
[RANK: 17] Initializing weights for WindowedPoolerMultiResMultiScaleV3Init.
[RANK: 22] Initializing weights for WindowedPoolerMultiResMultiScaleV3Init.
[RANK: 18] Initializing weights for WindowedPoolerMultiResMultiScaleV3Init.
[RANK: 23] Initializing weights for WindowedPoolerMultiResMultiScaleV3Init.
[RANK: 16] Initializing weights for WindowedPoolerMultiResMultiScaleV3Init.
[RANK: 20] Initializing weights for WindowedPoolerMultiResMultiScaleV3Init.
[RANK: 21] Initializing weights for WindowedPoolerMultiResMultiScaleV3Init.
[RANK: 19] Initializing weights for WindowedPoolerMultiResMultiScaleV3Init.
[mm_projector] keys in model not matched: []
[mm_projector] keys in checkpoint not matched: []
[mm_projector] keys in model not matched: []
[mm_projector] keys in checkpoint not matched: []
[mm_projector] keys in model not matched: []
[mm_projector] keys in checkpoint not matched: []
[mm_projector] keys in model not matched: []
[mm_projector] keys in checkpoint not matched: []
[mm_projector] keys in model not matched: []
[mm_projector] keys in checkpoint not matched: []
[mm_projector] keys in model not matched: []
[mm_projector] keys in checkpoint not matched: []
[mm_projector] keys in model not matched: []
[mm_projector] keys in checkpoint not matched: []
[mm_projector] keys in model not matched: []
[mm_projector] keys in checkpoint not matched: []
/opt/conda/envs/llava/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: 
dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)
  warnings.warn(
/opt/conda/envs/llava/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: 
dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)
  warnings.warn(
/opt/conda/envs/llava/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: 
dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)
  warnings.warn(
/opt/conda/envs/llava/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: 
dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)
  warnings.warn(
Formatting inputs...Skip in lazy mode
/opt/conda/envs/llava/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: 
dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)
  warnings.warn(
/opt/conda/envs/llava/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: 
dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)
  warnings.warn(
/opt/conda/envs/llava/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: 
dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)
  warnings.warn(
/opt/conda/envs/llava/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: 
dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)
  warnings.warn(
/opt/conda/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/opt/conda/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/opt/conda/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/opt/conda/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/opt/conda/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/opt/conda/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/opt/conda/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/opt/conda/envs/llava/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
aieflopsvip-kmaker-033145109241:224070:233410 [6] NCCL INFO Using non-device net plugin version 0
aieflopsvip-kmaker-033145109241:224071:233413 [7] NCCL INFO Using non-device net plugin version 0
aieflopsvip-kmaker-033145109241:224068:233412 [4] NCCL INFO Using non-device net plugin version 0
aieflopsvip-kmaker-033145109241:224065:233408 [1] NCCL INFO Using non-device net plugin version 0
aieflopsvip-kmaker-033145109241:224066:233414 [2] NCCL INFO Using non-device net plugin version 0
aieflopsvip-kmaker-033145109241:224064:233411 [0] NCCL INFO Using non-device net plugin version 0
aieflopsvip-kmaker-033145109241:224067:233407 [3] NCCL INFO Using non-device net plugin version 0
aieflopsvip-kmaker-033145109241:224070:233410 [6] NCCL INFO Using network IB
aieflopsvip-kmaker-033145109241:224071:233413 [7] NCCL INFO Using network IB
aieflopsvip-kmaker-033145109241:224068:233412 [4] NCCL INFO Using network IB
aieflopsvip-kmaker-033145109241:224069:233409 [5] NCCL INFO Using non-device net plugin version 0
aieflopsvip-kmaker-033145109241:224065:233408 [1] NCCL INFO Using network IB
aieflopsvip-kmaker-033145109241:224066:233414 [2] NCCL INFO Using network IB
aieflopsvip-kmaker-033145109241:224064:233411 [0] NCCL INFO Using network IB
aieflopsvip-kmaker-033145109241:224067:233407 [3] NCCL INFO Using network IB
aieflopsvip-kmaker-033145109241:224069:233409 [5] NCCL INFO Using network IB
aieflopsvip-kmaker-033145109241:224064:233411 [0] NCCL INFO bootstrapSplit: rank 16 nranks 32 color 698429859 key 16 prev 15 next 17 - DONE
aieflopsvip-kmaker-033145109241:224064:233411 [0] NCCL INFO comm 0x7f1f4004da30 rank 16 nranks 32 cudaDev 0 nvmlDev 0 busId 13000 commId 0x6ea2d0a76d1b134d - Init START
aieflopsvip-kmaker-033145109241:224065:233408 [1] NCCL INFO bootstrapSplit: rank 17 nranks 32 color 698429859 key 17 prev 16 next 18 - DONE
aieflopsvip-kmaker-033145109241:224067:233407 [3] NCCL INFO bootstrapSplit: rank 19 nranks 32 color 698429859 key 19 prev 18 next 20 - DONE
aieflopsvip-kmaker-033145109241:224070:233410 [6] NCCL INFO bootstrapSplit: rank 22 nranks 32 color 698429859 key 22 prev 21 next 23 - DONE
aieflopsvip-kmaker-033145109241:224068:233412 [4] NCCL INFO bootstrapSplit: rank 20 nranks 32 color 698429859 key 20 prev 19 next 21 - DONE
aieflopsvip-kmaker-033145109241:224066:233414 [2] NCCL INFO bootstrapSplit: rank 18 nranks 32 color 698429859 key 18 prev 17 next 19 - DONE
aieflopsvip-kmaker-033145109241:224069:233409 [5] NCCL INFO bootstrapSplit: rank 21 nranks 32 color 698429859 key 21 prev 20 next 22 - DONE
aieflopsvip-kmaker-033145109241:224071:233413 [7] NCCL INFO bootstrapSplit: rank 23 nranks 32 color 698429859 key 23 prev 22 next 24 - DONE
aieflopsvip-kmaker-033145109241:224065:233408 [1] NCCL INFO comm 0x7f4fa404d6e0 rank 17 nranks 32 cudaDev 1 nvmlDev 1 busId 19000 commId 0x6ea2d0a76d1b134d - Init START
aieflopsvip-kmaker-033145109241:224067:233407 [3] NCCL INFO comm 0x7f8af004d890 rank 19 nranks 32 cudaDev 3 nvmlDev 3 busId 4d000 commId 0x6ea2d0a76d1b134d - Init START
aieflopsvip-kmaker-033145109241:224070:233410 [6] NCCL INFO comm 0x7fc85404d5a0 rank 22 nranks 32 cudaDev 6 nvmlDev 6 busId ad000 commId 0x6ea2d0a76d1b134d - Init START
aieflopsvip-kmaker-033145109241:224068:233412 [4] NCCL INFO comm 0x7f04f004da10 rank 20 nranks 32 cudaDev 4 nvmlDev 4 busId 89000 commId 0x6ea2d0a76d1b134d - Init START
aieflopsvip-kmaker-033145109241:224066:233414 [2] NCCL INFO comm 0x7f19dc04d9f0 rank 18 nranks 32 cudaDev 2 nvmlDev 2 busId 48000 commId 0x6ea2d0a76d1b134d - Init START
aieflopsvip-kmaker-033145109241:224069:233409 [5] NCCL INFO comm 0x7fa8a404d0b0 rank 21 nranks 32 cudaDev 5 nvmlDev 5 busId 8e000 commId 0x6ea2d0a76d1b134d - Init START
aieflopsvip-kmaker-033145109241:224071:233413 [7] NCCL INFO comm 0x7f58f004d350 rank 23 nranks 32 cudaDev 7 nvmlDev 7 busId b3000 commId 0x6ea2d0a76d1b134d - Init START
aieflopsvip-kmaker-033145109241:224068:233412 [4] NCCL INFO Setting affinity for GPU 4 to ffffffff,00000000,ffffffff,00000000
aieflopsvip-kmaker-033145109241:224068:233412 [4] NCCL INFO NVLS multicast support is not available on dev 4
aieflopsvip-kmaker-033145109241:224065:233408 [1] NCCL INFO Setting affinity for GPU 1 to ffffffff,00000000,ffffffff
aieflopsvip-kmaker-033145109241:224065:233408 [1] NCCL INFO NVLS multicast support is not available on dev 1
aieflopsvip-kmaker-033145109241:224071:233413 [7] NCCL INFO Setting affinity for GPU 7 to ffffffff,00000000,ffffffff,00000000
aieflopsvip-kmaker-033145109241:224071:233413 [7] NCCL INFO NVLS multicast support is not available on dev 7
aieflopsvip-kmaker-033145109241:224069:233409 [5] NCCL INFO Setting affinity for GPU 5 to ffffffff,00000000,ffffffff,00000000
aieflopsvip-kmaker-033145109241:224069:233409 [5] NCCL INFO NVLS multicast support is not available on dev 5
aieflopsvip-kmaker-033145109241:224067:233407 [3] NCCL INFO Setting affinity for GPU 3 to ffffffff,00000000,ffffffff
aieflopsvip-kmaker-033145109241:224067:233407 [3] NCCL INFO NVLS multicast support is not available on dev 3
aieflopsvip-kmaker-033145109241:224066:233414 [2] NCCL INFO Setting affinity for GPU 2 to ffffffff,00000000,ffffffff
aieflopsvip-kmaker-033145109241:224066:233414 [2] NCCL INFO NVLS multicast support is not available on dev 2
aieflopsvip-kmaker-033145109241:224064:233411 [0] NCCL INFO Setting affinity for GPU 0 to ffffffff,00000000,ffffffff
aieflopsvip-kmaker-033145109241:224064:233411 [0] NCCL INFO NVLS multicast support is not available on dev 0
aieflopsvip-kmaker-033145109241:224070:233410 [6] NCCL INFO Setting affinity for GPU 6 to ffffffff,00000000,ffffffff,00000000
aieflopsvip-kmaker-033145109241:224070:233410 [6] NCCL INFO NVLS multicast support is not available on dev 6
aieflopsvip-kmaker-033145109241:224064:233411 [0] NCCL INFO Trees [0] 17/24/-1->16->0 [1] 17/-1/-1->16->23 [2] 17/-1/-1->16->23 [3] 17/-1/-1->16->23 [4] 17/-1/-1->16->9 [5] 17/-1/-1->16->23 [6] 17/-1/-1->16->23 [7] 17/-1/-1->16->23
aieflopsvip-kmaker-033145109241:224068:233412 [4] NCCL INFO Trees [0] 21/-1/-1->20->19 [1] 21/-1/-1->20->19 [2] 21/28/-1->20->4 [3] 21/-1/-1->20->19 [4] 21/-1/-1->20->19 [5] 21/-1/-1->20->19 [6] 21/-1/-1->20->13 [7] 21/-1/-1->20->19
aieflopsvip-kmaker-033145109241:224070:233410 [6] NCCL INFO Trees [0] 23/-1/-1->22->21 [1] 23/-1/-1->22->21 [2] 23/-1/-1->22->21 [3] 23/30/-1->22->6 [4] 23/-1/-1->22->21 [5] 23/-1/-1->22->21 [6] 23/-1/-1->22->21 [7] 23/-1/-1->22->15
aieflopsvip-kmaker-033145109241:224071:233413 [7] NCCL INFO Trees [0] -1/-1/-1->23->22 [1] 16/-1/-1->23->22 [2] 16/-1/-1->23->22 [3] 16/14/-1->23->22 [4] -1/-1/-1->23->22 [5] 16/-1/-1->23->22 [6] 16/-1/-1->23->22 [7] 16/-1/-1->23->22
aieflopsvip-kmaker-033145109241:224066:233414 [2] NCCL INFO Trees [0] 19/-1/-1->18->17 [1] 19/26/-1->18->2 [2] 19/-1/-1->18->17 [3] 19/-1/-1->18->17 [4] 19/-1/-1->18->17 [5] 19/-1/-1->18->11 [6] 19/-1/-1->18->17 [7] 19/-1/-1->18->17
aieflopsvip-kmaker-033145109241:224069:233409 [5] NCCL INFO Trees [0] 22/-1/-1->21->20 [1] 22/-1/-1->21->20 [2] 22/12/-1->21->20 [3] -1/-1/-1->21->20 [4] 22/-1/-1->21->20 [5] 22/-1/-1->21->20 [6] 22/-1/-1->21->20 [7] -1/-1/-1->21->20
aieflopsvip-kmaker-033145109241:224065:233408 [1] NCCL INFO Trees [0] 18/8/-1->17->16 [1] -1/-1/-1->17->16 [2] 18/-1/-1->17->16 [3] 18/-1/-1->17->16 [4] 18/-1/-1->17->16 [5] -1/-1/-1->17->16 [6] 18/-1/-1->17->16 [7] 18/-1/-1->17->16
aieflopsvip-kmaker-033145109241:224064:233411 [0] NCCL INFO P2P Chunksize set to 131072
aieflopsvip-kmaker-033145109241:224068:233412 [4] NCCL INFO P2P Chunksize set to 131072
aieflopsvip-kmaker-033145109241:224070:233410 [6] NCCL INFO P2P Chunksize set to 131072
aieflopsvip-kmaker-033145109241:224071:233413 [7] NCCL INFO P2P Chunksize set to 131072
aieflopsvip-kmaker-033145109241:224066:233414 [2] NCCL INFO P2P Chunksize set to 131072
aieflopsvip-kmaker-033145109241:224069:233409 [5] NCCL INFO P2P Chunksize set to 131072
aieflopsvip-kmaker-033145109241:224065:233408 [1] NCCL INFO P2P Chunksize set to 131072
aieflopsvip-kmaker-033145109241:224067:233407 [3] NCCL INFO Trees [0] 20/-1/-1->19->18 [1] 20/10/-1->19->18 [2] -1/-1/-1->19->18 [3] 20/-1/-1->19->18 [4] 20/-1/-1->19->18 [5] 20/-1/-1->19->18 [6] -1/-1/-1->19->18 [7] 20/-1/-1->19->18
aieflopsvip-kmaker-033145109241:224067:233407 [3] NCCL INFO P2P Chunksize set to 131072
aieflopsvip-kmaker-033145109241:224070:233410 [6] NCCL INFO Channel 03/0 : 15[7] -> 22[6] [receive] via NET/IB/2/GDRDMA
aieflopsvip-kmaker-033145109241:224070:233410 [6] NCCL INFO Channel 07/0 : 15[7] -> 22[6] [receive] via NET/IB/2/GDRDMA
aieflopsvip-kmaker-033145109241:224068:233412 [4] NCCL INFO Channel 02/0 : 13[5] -> 20[4] [receive] via NET/IB/1/GDRDMA
aieflopsvip-kmaker-033145109241:224068:233412 [4] NCCL INFO Channel 06/0 : 13[5] -> 20[4] [receive] via NET/IB/1/GDRDMA
aieflopsvip-kmaker-033145109241:224069:233409 [5] NCCL INFO Channel 02/0 : 21[5] -> 28[4] [send] via NET/IB/1/GDRDMA
aieflopsvip-kmaker-033145109241:224069:233409 [5] NCCL INFO Channel 06/0 : 21[5] -> 28[4] [send] via NET/IB/1/GDRDMA
aieflopsvip-kmaker-033145109241:224064:233411 [0] NCCL INFO Channel 00/0 : 9[1] -> 16[0] [receive] via NET/IB/0/GDRDMA
aieflopsvip-kmaker-033145109241:224065:233408 [1] NCCL INFO Channel 00/0 : 17[1] -> 24[0] [send] via NET/IB/0/GDRDMA
aieflopsvip-kmaker-033145109241:224065:233408 [1] NCCL INFO Channel 04/0 : 17[1] -> 24[0] [send] via NET/IB/0/GDRDMA
aieflopsvip-kmaker-033145109241:224064:233411 [0] NCCL INFO Channel 04/0 : 9[1] -> 16[0] [receive] via NET/IB/0/GDRDMA
aieflopsvip-kmaker-033145109241:224066:233414 [2] NCCL INFO Channel 01/0 : 11[3] -> 18[2] [receive] via NET/IB/3/GDRDMA
aieflopsvip-kmaker-033145109241:224064:233411 [0] NCCL INFO Channel 00/0 : 16[0] -> 23[7] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224066:233414 [2] NCCL INFO Channel 05/0 : 11[3] -> 18[2] [receive] via NET/IB/3/GDRDMA
aieflopsvip-kmaker-033145109241:224067:233407 [3] NCCL INFO Channel 01/0 : 19[3] -> 26[2] [send] via NET/IB/3/GDRDMA
aieflopsvip-kmaker-033145109241:224067:233407 [3] NCCL INFO Channel 05/0 : 19[3] -> 26[2] [send] via NET/IB/3/GDRDMA
aieflopsvip-kmaker-033145109241:224064:233411 [0] NCCL INFO Channel 01/0 : 16[0] -> 23[7] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224064:233411 [0] NCCL INFO Channel 02/0 : 16[0] -> 23[7] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224064:233411 [0] NCCL INFO Channel 03/0 : 16[0] -> 23[7] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224064:233411 [0] NCCL INFO Channel 04/0 : 16[0] -> 23[7] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224071:233413 [7] NCCL INFO Channel 03/0 : 23[7] -> 30[6] [send] via NET/IB/2/GDRDMA
aieflopsvip-kmaker-033145109241:224071:233413 [7] NCCL INFO Channel 07/0 : 23[7] -> 30[6] [send] via NET/IB/2/GDRDMA
aieflopsvip-kmaker-033145109241:224064:233411 [0] NCCL INFO Channel 05/0 : 16[0] -> 23[7] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224064:233411 [0] NCCL INFO Channel 06/0 : 16[0] -> 23[7] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224064:233411 [0] NCCL INFO Channel 07/0 : 16[0] -> 23[7] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224066:233414 [2] NCCL INFO Channel 00/0 : 18[2] -> 17[1] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224068:233412 [4] NCCL INFO Channel 00/0 : 20[4] -> 19[3] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224066:233414 [2] NCCL INFO Channel 01/0 : 18[2] -> 17[1] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224068:233412 [4] NCCL INFO Channel 01/0 : 20[4] -> 19[3] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224066:233414 [2] NCCL INFO Channel 02/0 : 18[2] -> 17[1] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224068:233412 [4] NCCL INFO Channel 02/0 : 20[4] -> 19[3] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224066:233414 [2] NCCL INFO Channel 03/0 : 18[2] -> 17[1] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224068:233412 [4] NCCL INFO Channel 03/0 : 20[4] -> 19[3] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224066:233414 [2] NCCL INFO Channel 04/0 : 18[2] -> 17[1] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224068:233412 [4] NCCL INFO Channel 04/0 : 20[4] -> 19[3] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224066:233414 [2] NCCL INFO Channel 05/0 : 18[2] -> 17[1] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224068:233412 [4] NCCL INFO Channel 05/0 : 20[4] -> 19[3] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224066:233414 [2] NCCL INFO Channel 06/0 : 18[2] -> 17[1] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224068:233412 [4] NCCL INFO Channel 06/0 : 20[4] -> 19[3] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224066:233414 [2] NCCL INFO Channel 07/0 : 18[2] -> 17[1] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224068:233412 [4] NCCL INFO Channel 07/0 : 20[4] -> 19[3] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224070:233410 [6] NCCL INFO Channel 00/0 : 22[6] -> 21[5] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224070:233410 [6] NCCL INFO Channel 01/0 : 22[6] -> 21[5] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224070:233410 [6] NCCL INFO Channel 02/0 : 22[6] -> 21[5] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224070:233410 [6] NCCL INFO Channel 03/0 : 22[6] -> 21[5] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224070:233410 [6] NCCL INFO Channel 04/0 : 22[6] -> 21[5] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224070:233410 [6] NCCL INFO Channel 05/0 : 22[6] -> 21[5] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224070:233410 [6] NCCL INFO Channel 06/0 : 22[6] -> 21[5] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224070:233410 [6] NCCL INFO Channel 07/0 : 22[6] -> 21[5] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224071:233413 [7] NCCL INFO Channel 00/0 : 23[7] -> 22[6] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224071:233413 [7] NCCL INFO Channel 01/0 : 23[7] -> 22[6] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224071:233413 [7] NCCL INFO Channel 02/0 : 23[7] -> 22[6] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224071:233413 [7] NCCL INFO Channel 04/0 : 23[7] -> 22[6] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224071:233413 [7] NCCL INFO Channel 05/0 : 23[7] -> 22[6] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224071:233413 [7] NCCL INFO Channel 06/0 : 23[7] -> 22[6] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224069:233409 [5] NCCL INFO Channel 00/0 : 21[5] -> 20[4] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224069:233409 [5] NCCL INFO Channel 01/0 : 21[5] -> 20[4] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224069:233409 [5] NCCL INFO Channel 03/0 : 21[5] -> 20[4] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224069:233409 [5] NCCL INFO Channel 04/0 : 21[5] -> 20[4] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224067:233407 [3] NCCL INFO Channel 00/0 : 19[3] -> 18[2] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224069:233409 [5] NCCL INFO Channel 05/0 : 21[5] -> 20[4] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224067:233407 [3] NCCL INFO Channel 02/0 : 19[3] -> 18[2] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224069:233409 [5] NCCL INFO Channel 07/0 : 21[5] -> 20[4] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224067:233407 [3] NCCL INFO Channel 03/0 : 19[3] -> 18[2] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224067:233407 [3] NCCL INFO Channel 04/0 : 19[3] -> 18[2] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224067:233407 [3] NCCL INFO Channel 06/0 : 19[3] -> 18[2] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224067:233407 [3] NCCL INFO Channel 07/0 : 19[3] -> 18[2] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224065:233408 [1] NCCL INFO Channel 01/0 : 17[1] -> 16[0] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224065:233408 [1] NCCL INFO Channel 02/0 : 17[1] -> 16[0] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224065:233408 [1] NCCL INFO Channel 03/0 : 17[1] -> 16[0] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224065:233408 [1] NCCL INFO Channel 05/0 : 17[1] -> 16[0] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224065:233408 [1] NCCL INFO Channel 06/0 : 17[1] -> 16[0] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224065:233408 [1] NCCL INFO Channel 07/0 : 17[1] -> 16[0] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224067:233407 [3] NCCL INFO Connected all rings
aieflopsvip-kmaker-033145109241:224067:233407 [3] NCCL INFO Channel 00/0 : 19[3] -> 20[4] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224067:233407 [3] NCCL INFO Channel 01/0 : 19[3] -> 20[4] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224067:233407 [3] NCCL INFO Channel 03/0 : 19[3] -> 20[4] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224067:233407 [3] NCCL INFO Channel 04/0 : 19[3] -> 20[4] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224067:233407 [3] NCCL INFO Channel 05/0 : 19[3] -> 20[4] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224067:233407 [3] NCCL INFO Channel 07/0 : 19[3] -> 20[4] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224068:233412 [4] NCCL INFO Connected all rings
aieflopsvip-kmaker-033145109241:224069:233409 [5] NCCL INFO Connected all rings
aieflopsvip-kmaker-033145109241:224068:233412 [4] NCCL INFO Channel 00/0 : 20[4] -> 21[5] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224068:233412 [4] NCCL INFO Channel 01/0 : 20[4] -> 21[5] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224068:233412 [4] NCCL INFO Channel 02/0 : 20[4] -> 21[5] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224068:233412 [4] NCCL INFO Channel 03/0 : 20[4] -> 21[5] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224064:233411 [0] NCCL INFO Connected all rings
aieflopsvip-kmaker-033145109241:224065:233408 [1] NCCL INFO Connected all rings
aieflopsvip-kmaker-033145109241:224064:233411 [0] NCCL INFO Channel 00/0 : 16[0] -> 17[1] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224066:233414 [2] NCCL INFO Connected all rings
aieflopsvip-kmaker-033145109241:224069:233409 [5] NCCL INFO Channel 00/0 : 21[5] -> 22[6] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224068:233412 [4] NCCL INFO Channel 04/0 : 20[4] -> 21[5] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224064:233411 [0] NCCL INFO Channel 01/0 : 16[0] -> 17[1] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224069:233409 [5] NCCL INFO Channel 01/0 : 21[5] -> 22[6] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224068:233412 [4] NCCL INFO Channel 05/0 : 20[4] -> 21[5] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224071:233413 [7] NCCL INFO Connected all rings
aieflopsvip-kmaker-033145109241:224064:233411 [0] NCCL INFO Channel 02/0 : 16[0] -> 17[1] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224069:233409 [5] NCCL INFO Channel 02/0 : 21[5] -> 22[6] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224068:233412 [4] NCCL INFO Channel 06/0 : 20[4] -> 21[5] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224070:233410 [6] NCCL INFO Connected all rings
aieflopsvip-kmaker-033145109241:224064:233411 [0] NCCL INFO Channel 03/0 : 16[0] -> 17[1] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224069:233409 [5] NCCL INFO Channel 04/0 : 21[5] -> 22[6] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224068:233412 [4] NCCL INFO Channel 07/0 : 20[4] -> 21[5] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224064:233411 [0] NCCL INFO Channel 04/0 : 16[0] -> 17[1] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224069:233409 [5] NCCL INFO Channel 05/0 : 21[5] -> 22[6] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224069:233409 [5] NCCL INFO Channel 06/0 : 21[5] -> 22[6] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224064:233411 [0] NCCL INFO Channel 05/0 : 16[0] -> 17[1] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224066:233414 [2] NCCL INFO Channel 00/0 : 18[2] -> 19[3] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224068:233412 [4] NCCL INFO Channel 02/0 : 20[4] -> 28[4] [send] via NET/IB/1/GDRDMA
aieflopsvip-kmaker-033145109241:224064:233411 [0] NCCL INFO Channel 06/0 : 16[0] -> 17[1] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224066:233414 [2] NCCL INFO Channel 01/0 : 18[2] -> 19[3] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224064:233411 [0] NCCL INFO Channel 07/0 : 16[0] -> 17[1] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224066:233414 [2] NCCL INFO Channel 02/0 : 18[2] -> 19[3] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224065:233408 [1] NCCL INFO Channel 00/0 : 17[1] -> 18[2] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224070:233410 [6] NCCL INFO Channel 00/0 : 22[6] -> 23[7] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224066:233414 [2] NCCL INFO Channel 03/0 : 18[2] -> 19[3] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224065:233408 [1] NCCL INFO Channel 02/0 : 17[1] -> 18[2] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224070:233410 [6] NCCL INFO Channel 01/0 : 22[6] -> 23[7] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224066:233414 [2] NCCL INFO Channel 04/0 : 18[2] -> 19[3] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224065:233408 [1] NCCL INFO Channel 03/0 : 17[1] -> 18[2] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224070:233410 [6] NCCL INFO Channel 02/0 : 22[6] -> 23[7] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224066:233414 [2] NCCL INFO Channel 05/0 : 18[2] -> 19[3] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224065:233408 [1] NCCL INFO Channel 04/0 : 17[1] -> 18[2] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224070:233410 [6] NCCL INFO Channel 03/0 : 22[6] -> 23[7] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224066:233414 [2] NCCL INFO Channel 06/0 : 18[2] -> 19[3] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224065:233408 [1] NCCL INFO Channel 06/0 : 17[1] -> 18[2] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224070:233410 [6] NCCL INFO Channel 04/0 : 22[6] -> 23[7] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224066:233414 [2] NCCL INFO Channel 07/0 : 18[2] -> 19[3] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224065:233408 [1] NCCL INFO Channel 07/0 : 17[1] -> 18[2] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224070:233410 [6] NCCL INFO Channel 05/0 : 22[6] -> 23[7] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224064:233411 [0] NCCL INFO Channel 00/0 : 16[0] -> 24[0] [send] via NET/IB/0/GDRDMA
aieflopsvip-kmaker-033145109241:224066:233414 [2] NCCL INFO Channel 01/0 : 18[2] -> 26[2] [send] via NET/IB/3/GDRDMA
aieflopsvip-kmaker-033145109241:224070:233410 [6] NCCL INFO Channel 06/0 : 22[6] -> 23[7] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224065:233408 [1] NCCL INFO Channel 00/0 : 8[0] -> 17[1] [receive] via NET/IB/0/GDRDMA
aieflopsvip-kmaker-033145109241:224067:233407 [3] NCCL INFO Channel 01/0 : 10[2] -> 19[3] [receive] via NET/IB/3/GDRDMA
aieflopsvip-kmaker-033145109241:224070:233410 [6] NCCL INFO Channel 07/0 : 22[6] -> 23[7] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224069:233409 [5] NCCL INFO Channel 02/0 : 12[4] -> 21[5] [receive] via NET/IB/1/GDRDMA
aieflopsvip-kmaker-033145109241:224070:233410 [6] NCCL INFO Channel 03/0 : 22[6] -> 30[6] [send] via NET/IB/2/GDRDMA
aieflopsvip-kmaker-033145109241:224071:233413 [7] NCCL INFO Channel 03/0 : 14[6] -> 23[7] [receive] via NET/IB/2/GDRDMA
aieflopsvip-kmaker-033145109241:224064:233411 [0] NCCL INFO Channel 00/0 : 0[0] -> 16[0] [receive] via NET/IB/0/GDRDMA
aieflopsvip-kmaker-033145109241:224064:233411 [0] NCCL INFO Channel 00/0 : 16[0] -> 0[0] [send] via NET/IB/0/GDRDMA
aieflopsvip-kmaker-033145109241:224070:233410 [6] NCCL INFO Channel 03/0 : 6[6] -> 22[6] [receive] via NET/IB/2/GDRDMA
aieflopsvip-kmaker-033145109241:224070:233410 [6] NCCL INFO Channel 03/0 : 22[6] -> 6[6] [send] via NET/IB/2/GDRDMA
aieflopsvip-kmaker-033145109241:224066:233414 [2] NCCL INFO Channel 01/0 : 2[2] -> 18[2] [receive] via NET/IB/3/GDRDMA
aieflopsvip-kmaker-033145109241:224066:233414 [2] NCCL INFO Channel 01/0 : 18[2] -> 2[2] [send] via NET/IB/3/GDRDMA
aieflopsvip-kmaker-033145109241:224068:233412 [4] NCCL INFO Channel 02/0 : 4[4] -> 20[4] [receive] via NET/IB/1/GDRDMA
aieflopsvip-kmaker-033145109241:224068:233412 [4] NCCL INFO Channel 02/0 : 20[4] -> 4[4] [send] via NET/IB/1/GDRDMA
aieflopsvip-kmaker-033145109241:224070:233410 [6] NCCL INFO Channel 03/0 : 30[6] -> 22[6] [receive] via NET/IB/2/GDRDMA
aieflopsvip-kmaker-033145109241:224067:233407 [3] NCCL INFO Channel 01/0 : 19[3] -> 10[2] [send] via NET/IB/3/GDRDMA
aieflopsvip-kmaker-033145109241:224068:233412 [4] NCCL INFO Channel 02/0 : 28[4] -> 20[4] [receive] via NET/IB/1/GDRDMA
aieflopsvip-kmaker-033145109241:224071:233413 [7] NCCL INFO Channel 03/0 : 23[7] -> 14[6] [send] via NET/IB/2/GDRDMA
aieflopsvip-kmaker-033145109241:224070:233410 [6] NCCL INFO Channel 07/0 : 22[6] -> 15[7] [send] via NET/IB/2/GDRDMA
aieflopsvip-kmaker-033145109241:224068:233412 [4] NCCL INFO Channel 06/0 : 20[4] -> 13[5] [send] via NET/IB/1/GDRDMA
aieflopsvip-kmaker-033145109241:224071:233413 [7] NCCL INFO Channel 01/0 : 23[7] -> 16[0] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224064:233411 [0] NCCL INFO Channel 00/0 : 24[0] -> 16[0] [receive] via NET/IB/0/GDRDMA
aieflopsvip-kmaker-033145109241:224066:233414 [2] NCCL INFO Channel 01/0 : 26[2] -> 18[2] [receive] via NET/IB/3/GDRDMA
aieflopsvip-kmaker-033145109241:224065:233408 [1] NCCL INFO Channel 00/0 : 17[1] -> 8[0] [send] via NET/IB/0/GDRDMA
aieflopsvip-kmaker-033145109241:224069:233409 [5] NCCL INFO Channel 02/0 : 21[5] -> 12[4] [send] via NET/IB/1/GDRDMA
aieflopsvip-kmaker-033145109241:224065:233408 [1] NCCL INFO Channel 00/0 : 17[1] -> 16[0] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224069:233409 [5] NCCL INFO Channel 02/0 : 21[5] -> 20[4] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224066:233414 [2] NCCL INFO Channel 05/0 : 18[2] -> 11[3] [send] via NET/IB/3/GDRDMA
aieflopsvip-kmaker-033145109241:224067:233407 [3] NCCL INFO Channel 01/0 : 19[3] -> 18[2] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224071:233413 [7] NCCL INFO Channel 02/0 : 23[7] -> 16[0] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224065:233408 [1] NCCL INFO Channel 04/0 : 17[1] -> 16[0] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224069:233409 [5] NCCL INFO Channel 06/0 : 21[5] -> 20[4] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224067:233407 [3] NCCL INFO Channel 05/0 : 19[3] -> 18[2] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224071:233413 [7] NCCL INFO Channel 03/0 : 23[7] -> 16[0] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224071:233413 [7] NCCL INFO Channel 05/0 : 23[7] -> 16[0] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224071:233413 [7] NCCL INFO Channel 06/0 : 23[7] -> 16[0] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224071:233413 [7] NCCL INFO Channel 07/0 : 23[7] -> 16[0] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224064:233411 [0] NCCL INFO Channel 04/0 : 16[0] -> 9[1] [send] via NET/IB/0/GDRDMA
aieflopsvip-kmaker-033145109241:224071:233413 [7] NCCL INFO Channel 03/0 : 23[7] -> 22[6] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224071:233413 [7] NCCL INFO Channel 07/0 : 23[7] -> 22[6] via P2P/CUMEM/read
aieflopsvip-kmaker-033145109241:224069:233409 [5] NCCL INFO Connected all trees
aieflopsvip-kmaker-033145109241:224068:233412 [4] NCCL INFO Connected all trees
aieflopsvip-kmaker-033145109241:224069:233409 [5] NCCL INFO threadThresholds 8/8/64 | 256/8/64 | 512 | 512
aieflopsvip-kmaker-033145109241:224069:233409 [5] NCCL INFO 8 coll channels, 0 nvls channels, 8 p2p channels, 2 p2p channels per peer
aieflopsvip-kmaker-033145109241:224068:233412 [4] NCCL INFO threadThresholds 8/8/64 | 256/8/64 | 512 | 512
aieflopsvip-kmaker-033145109241:224068:233412 [4] NCCL INFO 8 coll channels, 0 nvls channels, 8 p2p channels, 2 p2p channels per peer
aieflopsvip-kmaker-033145109241:224070:233410 [6] NCCL INFO Connected all trees
aieflopsvip-kmaker-033145109241:224071:233413 [7] NCCL INFO Connected all trees
aieflopsvip-kmaker-033145109241:224064:233411 [0] NCCL INFO Connected all trees
aieflopsvip-kmaker-033145109241:224065:233408 [1] NCCL INFO Connected all trees
aieflopsvip-kmaker-033145109241:224070:233410 [6] NCCL INFO threadThresholds 8/8/64 | 256/8/64 | 512 | 512
aieflopsvip-kmaker-033145109241:224071:233413 [7] NCCL INFO threadThresholds 8/8/64 | 256/8/64 | 512 | 512
aieflopsvip-kmaker-033145109241:224070:233410 [6] NCCL INFO 8 coll channels, 0 nvls channels, 8 p2p channels, 2 p2p channels per peer
aieflopsvip-kmaker-033145109241:224071:233413 [7] NCCL INFO 8 coll channels, 0 nvls channels, 8 p2p channels, 2 p2p channels per peer
aieflopsvip-kmaker-033145109241:224064:233411 [0] NCCL INFO threadThresholds 8/8/64 | 256/8/64 | 512 | 512
aieflopsvip-kmaker-033145109241:224064:233411 [0] NCCL INFO 8 coll channels, 0 nvls channels, 8 p2p channels, 2 p2p channels per peer
aieflopsvip-kmaker-033145109241:224065:233408 [1] NCCL INFO threadThresholds 8/8/64 | 256/8/64 | 512 | 512
aieflopsvip-kmaker-033145109241:224065:233408 [1] NCCL INFO 8 coll channels, 0 nvls channels, 8 p2p channels, 2 p2p channels per peer
aieflopsvip-kmaker-033145109241:224066:233414 [2] NCCL INFO Connected all trees
aieflopsvip-kmaker-033145109241:224066:233414 [2] NCCL INFO threadThresholds 8/8/64 | 256/8/64 | 512 | 512
aieflopsvip-kmaker-033145109241:224066:233414 [2] NCCL INFO 8 coll channels, 0 nvls channels, 8 p2p channels, 2 p2p channels per peer
aieflopsvip-kmaker-033145109241:224067:233407 [3] NCCL INFO Connected all trees
aieflopsvip-kmaker-033145109241:224067:233407 [3] NCCL INFO threadThresholds 8/8/64 | 256/8/64 | 512 | 512
aieflopsvip-kmaker-033145109241:224067:233407 [3] NCCL INFO 8 coll channels, 0 nvls channels, 8 p2p channels, 2 p2p channels per peer
aieflopsvip-kmaker-033145109241:224070:233410 [6] NCCL INFO comm 0x7fc85404d5a0 rank 22 nranks 32 cudaDev 6 nvmlDev 6 busId ad000 commId 0x6ea2d0a76d1b134d - Init COMPLETE
aieflopsvip-kmaker-033145109241:224066:233414 [2] NCCL INFO comm 0x7f19dc04d9f0 rank 18 nranks 32 cudaDev 2 nvmlDev 2 busId 48000 commId 0x6ea2d0a76d1b134d - Init COMPLETE
aieflopsvip-kmaker-033145109241:224065:233408 [1] NCCL INFO comm 0x7f4fa404d6e0 rank 17 nranks 32 cudaDev 1 nvmlDev 1 busId 19000 commId 0x6ea2d0a76d1b134d - Init COMPLETE
aieflopsvip-kmaker-033145109241:224071:233413 [7] NCCL INFO comm 0x7f58f004d350 rank 23 nranks 32 cudaDev 7 nvmlDev 7 busId b3000 commId 0x6ea2d0a76d1b134d - Init COMPLETE
aieflopsvip-kmaker-033145109241:224069:233409 [5] NCCL INFO comm 0x7fa8a404d0b0 rank 21 nranks 32 cudaDev 5 nvmlDev 5 busId 8e000 commId 0x6ea2d0a76d1b134d - Init COMPLETE
aieflopsvip-kmaker-033145109241:224067:233407 [3] NCCL INFO comm 0x7f8af004d890 rank 19 nranks 32 cudaDev 3 nvmlDev 3 busId 4d000 commId 0x6ea2d0a76d1b134d - Init COMPLETE
aieflopsvip-kmaker-033145109241:224068:233412 [4] NCCL INFO comm 0x7f04f004da10 rank 20 nranks 32 cudaDev 4 nvmlDev 4 busId 89000 commId 0x6ea2d0a76d1b134d - Init COMPLETE
aieflopsvip-kmaker-033145109241:224064:233411 [0] NCCL INFO comm 0x7f1f4004da30 rank 16 nranks 32 cudaDev 0 nvmlDev 0 busId 13000 commId 0x6ea2d0a76d1b134d - Init COMPLETE
/opt/conda/envs/llava/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/opt/conda/envs/llava/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/opt/conda/envs/llava/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/opt/conda/envs/llava/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/opt/conda/envs/llava/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/opt/conda/envs/llava/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/opt/conda/envs/llava/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/opt/conda/envs/llava/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[2024-08-26 17:47:43,278] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 224066 closing signal SIGTERM
[2024-08-26 17:47:43,278] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 224067 closing signal SIGTERM
[2024-08-26 17:47:43,278] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 224068 closing signal SIGTERM
[2024-08-26 17:47:43,278] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 224069 closing signal SIGTERM
[2024-08-26 17:47:43,278] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 224070 closing signal SIGTERM
[2024-08-26 17:47:44,895] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: -9) local_rank: 0 (pid: 224064) of binary: /opt/conda/envs/llava/bin/python
Traceback (most recent call last):
  File "/opt/conda/envs/llava/bin/torchrun", line 33, in <module>
    sys.exit(load_entry_point('torch==2.2.1', 'console_scripts', 'torchrun')())
  File "/opt/conda/envs/llava/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 347, in wrapper
    return f(*args, **kwargs)
  File "/opt/conda/envs/llava/lib/python3.10/site-packages/torch/distributed/run.py", line 812, in main
    run(args)
  File "/opt/conda/envs/llava/lib/python3.10/site-packages/torch/distributed/run.py", line 803, in run
    elastic_launch(
  File "/opt/conda/envs/llava/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 135, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/opt/conda/envs/llava/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
=======================================================
llava/train/train_mem.py FAILED
-------------------------------------------------------
Failures:
[1]:
  time      : 2024-08-26_17:47:43
  host      : aieflopsvip-kmaker-033145109241
  rank      : 17 (local_rank: 1)
  exitcode  : -9 (pid: 224065)
  error_file: <N/A>
  traceback : Signal 9 (SIGKILL) received by PID 224065
[2]:
  time      : 2024-08-26_17:47:43
  host      : aieflopsvip-kmaker-033145109241
  rank      : 23 (local_rank: 7)
  exitcode  : -9 (pid: 224071)
  error_file: <N/A>
  traceback : Signal 9 (SIGKILL) received by PID 224071
-------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-08-26_17:47:43
  host      : aieflopsvip-kmaker-033145109241
  rank      : 16 (local_rank: 0)
  exitcode  : -9 (pid: 224064)
  error_file: <N/A>
  traceback : Signal 9 (SIGKILL) received by PID 224064
=======================================================
